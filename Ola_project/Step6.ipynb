{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Optimization with uncertain conversion rates, ùõº ratios, and number of items sold per product,\n",
    "uncertain graph weight s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncertain graph weights (different click influence probabilities between the products for each user)\n",
    "#homogeneous users (one class with small variability)\n",
    "#uncertain alphas\n",
    "#uncertain number of items sold per product\n",
    "#uncertain conversion rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Environment.E_commerce import *\n",
    "from Algorithms.Conv_rates_Learner import *\n",
    "from Algorithms.TS_Learner_poisson import *\n",
    "from Algorithms.Learner_Environment import *\n",
    "from Algorithms.SWTS_Learner import *\n",
    "from Algorithms.UCB_Learner import *\n",
    "from Algorithms.Greedy_Learner import *\n",
    "from Algorithms.Estimate_click_probabilities import *\n",
    "from Algorithms.SW_UCB_Learner import SW_UCB\n",
    "from Algorithms.CD_UCB_Learner import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = Product(0,[9,12,13,14.5],[ 1.,  4,  5., 6.5])\n",
    "P2 = Product(1,[20,22.5,23,24.5],[ 4.,  6.5, 7., 8.5])\n",
    "P3 = Product(2,[30,31.5,34,34.5],[ 6.,  7.5, 10., 10.5])\n",
    "P4 = Product(3,[40,42.5,43,46.5],[ 8., 10.5, 11., 14.5])\n",
    "P5 = Product(4,[50,51.5,53,54.5],[10., 11.5, 13., 14.5])\n",
    "\n",
    "products = [P1,P2,P3,P4,P5]\n",
    "margins_matrix = np.zeros((5,4))\n",
    "expected_units_sold_per_product = np.array([2,1,3,3,1]) #theese are the lambdas defined in the visit function\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        margins_matrix[i,j] = products[i].margins_list[j]\n",
    "E = E_commerce()\n",
    "E.set_lambda(0.5)\n",
    "E.set_products(products)\n",
    "\n",
    "#Ecommerce graph weights are uncertain, for each user they are different, but the slots are fixed by the Ecommerce\n",
    "E.graph = np.array([[0. , 0.5, 0. , 1. , 0. ],[1. , 0. , 0. , 0.5, 0. ],[0. , 1. , 0. , 0.5, 0. ],[0. , 0.5, 1. , 0. , 0. ],[1. , 0. , 0. , 0.5, 0. ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________\n",
      "Conversion rates\n",
      "[[0.86608823 0.60924064 0.51224508 0.38379014]\n",
      " [0.79080749 0.56391525 0.51584067 0.38583686]\n",
      " [0.79036782 0.65293498 0.40839703 0.37308809]\n",
      " [0.78923949 0.5659224  0.52146642 0.22520458]\n",
      " [0.75625034 0.5951842  0.43184363 0.31123526]]\n",
      "_______________________________________________\n",
      "Expected rewards per arm\n",
      "[[ 1.73402991  4.84693313  5.06393787  4.91565168]\n",
      " [ 3.15184296  3.62306044  3.57108711  3.23047513]\n",
      " [14.17672512 14.53441291 11.99811047 11.53537891]\n",
      " [18.92585065 17.71890694 17.09794002  9.66843575]\n",
      " [ 7.56931162  6.84753092  5.61154378  4.50567612]]\n",
      "_______________________________________________\n",
      "Expected units sold per arm\n",
      "[[2. 2. 2. 2.]\n",
      " [1. 1. 1. 1.]\n",
      " [3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]\n",
      " [1. 1. 1. 1.]]\n",
      "_______________________________________________\n",
      "Best configuration [2. 1. 1. 0. 0.]\n",
      "Optimal cumulative expected reward per round\n",
      "50.05900574350898\n"
     ]
    }
   ],
   "source": [
    "#Random algorithm which for each round pulls a random choice \n",
    "#to estimate asymptotically the conv_rates and the mean of the number of units sold per product,\n",
    "#useful for computing clairvoyant solution and regrets of the bandit algorithms\n",
    "\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 1000\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1\n",
    "num_experiments = 10\n",
    "opt_vector = np.zeros(num_experiments)\n",
    "conv_rates_per_experiment = []\n",
    "mean_units_sold_per_product_per_eperiment = []\n",
    "cr_learner_expected_rewards_per_experiment = []\n",
    "\n",
    "for e in range(num_experiments):\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha, fixed_weights,fixed_units)\n",
    "    cr_learner = Conv_rates(n_arms=n_arms)\n",
    "\n",
    "    for d in range(n_days):\n",
    "        #if (d==30):\n",
    "        #    User0.setprice()\n",
    "        pulled_arm = cr_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        cr_learner.update(pulled_arm, reward, env.clicks_current_day, env.purchases_current_day,env.daily_units)\n",
    "\n",
    "\n",
    "    conversion_rates = np.zeros((5,4))\n",
    "    np.set_printoptions(suppress=True)\n",
    "    for i in range(5):\n",
    "        conversion_rates[i] = cr_learner.beta_parameters[i][:,0]/(cr_learner.beta_parameters[i][:,0]+cr_learner.beta_parameters[i][:,1])\n",
    "        opt_vector[e] += np.max(np.array(E.products[i].margins_list) * conversion_rates[i] * cr_learner.lambda_poisson[i])\n",
    "\n",
    "    conv_rates_per_experiment.append(conversion_rates)\n",
    "    mean_units_sold_per_product_per_eperiment.append(cr_learner.lambda_poisson)\n",
    "    cr_learner_expected_rewards_per_experiment.append(cr_learner.expected_rewards)\n",
    "\n",
    "#optimal expected clarvoyant solution is given chosing each round the best combination\n",
    "opt = np.mean(opt_vector) #+ np.std(opt_vector)\n",
    "best_arm_per_product = np.zeros(5)\n",
    "for i in range(5):   \n",
    "    best_arm_per_product[i] = np.argmax(np.array(E.products[i].margins_list) * np.mean(conv_rates_per_experiment,axis=0)[i] \n",
    "                                        * np.mean(mean_units_sold_per_product_per_eperiment, axis = 0)[i])#expected_units_sold_per_product[i])#\n",
    "    \n",
    "print(\"_______________________________________________\")\n",
    "print(\"Conversion rates\")\n",
    "print(np.mean(conv_rates_per_experiment,axis=0))\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Expected rewards per arm\")\n",
    "print(np.mean(cr_learner_expected_rewards_per_experiment,axis=0))\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Expected units sold per arm\")\n",
    "print(np.mean(mean_units_sold_per_product_per_eperiment, axis = 0))\n",
    "\n",
    "print(\"_______________________________________________\")\n",
    "print(\"Best configuration\", best_arm_per_product)\n",
    "print(\"Optimal cumulative expected reward per round\")\n",
    "print(opt) # optimal configuration: the best combination of arms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SW-TS (skip it)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It was not asked, but I wrote it. Unfortunately, it is giving some errors sometimes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 2.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 2.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 2.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 2.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [2. 3.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 2.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 2.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [2. 3.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [2. 2.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 2.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 2.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [2. 3.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [2. 2.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 4.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 2.]\n",
      "  [1. 1.]]]\n",
      "[[[4. 0.]\n",
      "  [4. 2.]\n",
      "  [1. 3.]\n",
      "  [1. 2.]]\n",
      "\n",
      " [[6. 2.]\n",
      "  [4. 0.]\n",
      "  [2. 2.]\n",
      "  [2. 3.]]\n",
      "\n",
      " [[5. 0.]\n",
      "  [3. 0.]\n",
      "  [2. 1.]\n",
      "  [2. 2.]]\n",
      "\n",
      " [[7. 1.]\n",
      "  [2. 3.]\n",
      "  [2. 5.]\n",
      "  [1. 4.]]\n",
      "\n",
      " [[2. 1.]\n",
      "  [2. 1.]\n",
      "  [1. 2.]\n",
      "  [0. 3.]]]\n",
      "cond1 False\n",
      "cond2 True\n",
      "beta1 [4. 4. 1. 1.]\n",
      "beta1-b [5. 5. 2. 2.]\n",
      "beta2 [0. 2. 3. 2.]\n",
      "beta2-b [1. 3. 4. 3.]\n",
      "3.0\n",
      "cond1 False\n",
      "cond2 True\n",
      "beta1 [6. 4. 2. 2.]\n",
      "beta1-b [7. 5. 3. 3.]\n",
      "beta2 [2. 0. 2. 3.]\n",
      "beta2-b [3. 1. 3. 4.]\n",
      "1.0\n",
      "cond1 False\n",
      "cond2 True\n",
      "beta1 [5. 3. 2. 2.]\n",
      "beta1-b [6. 4. 3. 3.]\n",
      "beta2 [0. 0. 1. 2.]\n",
      "beta2-b [1. 1. 2. 3.]\n",
      "1.0\n",
      "cond1 True\n",
      "cond2 False\n",
      "beta1 [2. 2. 1. 0.]\n",
      "beta1-b [3. 3. 2. 1.]\n",
      "beta2 [1. 1. 2. 3.]\n",
      "beta2-b [2. 2. 3. 4.]\n",
      "0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [157]\u001B[0m, in \u001B[0;36m<cell line: 20>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     30\u001B[0m     ts_learner\u001B[38;5;241m.\u001B[39mupdate(pulled_arm, reward,env\u001B[38;5;241m.\u001B[39mclicks_current_day, env\u001B[38;5;241m.\u001B[39mpurchases_current_day,  env\u001B[38;5;241m.\u001B[39mdaily_units)\n\u001B[1;32m     32\u001B[0m     pulled_arm \u001B[38;5;241m=\u001B[39m swts_learner\u001B[38;5;241m.\u001B[39mpull_arm(env\u001B[38;5;241m.\u001B[39mmargins_matrix)\n\u001B[0;32m---> 33\u001B[0m     reward \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mround\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpulled_arm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     swts_learner\u001B[38;5;241m.\u001B[39mupdate(pulled_arm, reward, env\u001B[38;5;241m.\u001B[39mclicks_current_day, env\u001B[38;5;241m.\u001B[39mpurchases_current_day, env\u001B[38;5;241m.\u001B[39mdaily_units)\n\u001B[1;32m     36\u001B[0m swts_rewards_per_experiment\u001B[38;5;241m.\u001B[39mappend(swts_learner\u001B[38;5;241m.\u001B[39mcollected_rewards)\n",
      "File \u001B[0;32m~/Documents/GitHub/OLA_Project/Ola_project/Algorithms/Learner_Environment.py:30\u001B[0m, in \u001B[0;36mEnvironment.round\u001B[0;34m(self, pulled_arm)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03m\"\"\"For each product, it changes the price corresponding to the pulled arm\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;124;03m:param pulled_arm: vector with pulled prices\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;03m:type pulled_arm: ndarray\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;03m:return: reward\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mE\u001B[38;5;241m.\u001B[39mproducts[i]\u001B[38;5;241m.\u001B[39mchange_price(\u001B[38;5;28mint\u001B[39m(\u001B[43mpulled_arm\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m))\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Reward is given thanks to the simulation of a day in the E-commerce website\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mE\u001B[38;5;241m.\u001B[39msimulate_day(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_users, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixed_alpha, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixed_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixed_units)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#Comparison between TS and SW-TS\n",
    "from Algorithms.SWTS_Learner import *\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 1000\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 10\n",
    "\n",
    "window_size = 100\n",
    "\n",
    "swts_rewards_per_experiment = []\n",
    "ts_rewards_per_experiment = []\n",
    "\n",
    "swts_pulls_per_arm_per_experiment = []\n",
    "ts_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ts_learner = TS_poisson(n_arms=n_arms)\n",
    "    swts_learner = SW_TS(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "\n",
    "        pulled_arm = ts_learner.pull_arm(env.margins_matrix)\n",
    "        reward = env.round(pulled_arm)\n",
    "        ts_learner.update(pulled_arm, reward,env.clicks_current_day, env.purchases_current_day,  env.daily_units)\n",
    "\n",
    "        pulled_arm = swts_learner.pull_arm(env.margins_matrix)\n",
    "        reward = env.round(pulled_arm)\n",
    "        swts_learner.update(pulled_arm, reward, env.clicks_current_day, env.purchases_current_day, env.daily_units)\n",
    "\n",
    "    swts_rewards_per_experiment.append(swts_learner.collected_rewards)\n",
    "    ts_rewards_per_experiment.append(ts_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    swts_pulls_per_arm_per_experiment.append(swts_learner.counter_per_arm)\n",
    "    ts_pulls_per_arm_per_experiment.append(ts_learner.counter_per_arm)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucamainini/opt/anaconda3/envs/math_environment/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/lucamainini/opt/anaconda3/envs/math_environment/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/lucamainini/opt/anaconda3/envs/math_environment/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/lucamainini/opt/anaconda3/envs/math_environment/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt - swts_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(opt - ts_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"Greedy\",\"TS\",\"UCB\",\"random\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TEST IF FUNCTION CORRECTLY WORKS (skip it)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 1000\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 10\n",
    "\n",
    "window_size = 100\n",
    "\n",
    "swts_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "ts_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "ts_learner = TS_poisson(n_arms=n_arms)\n",
    "swts_learner = SW_TS(n_arms, window_size)\n",
    "\n",
    "\n",
    "pulled_arm = ts_learner.pull_arm(env.margins_matrix)\n",
    "print(pulled_arm)\n",
    "reward = env.round(pulled_arm)\n",
    "#swts_learner.update(pulled_arm, reward, env.clicks_current_day, env.purchases_current_day, env.daily_units)\n",
    "swts_learner.t += 1\n",
    "swts_learner.update_observations(pulled_arm, reward)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 4. 9. 6. 3.]\n",
      "[3. 4. 3. 2. 3.]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#print(swts_learner.beta_parameters)\n",
    "print(env.daily_units)\n",
    "print(env.purchases_current_day)\n",
    "print(pulled_arm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks:  [[[8.0], [0], [0], [0]], [[6.0], [0], [0], [0]], [[5.0], [0], [0], [0]], [[7.0], [0], [0], [0]], [[3.0], [0], [0], [0]]]\n",
      "purchases [[[4.0], [0], [0], [0]], [[4.0], [0], [0], [0]], [[4.0], [0], [0], [0]], [[5.0], [0], [0], [0]], [[3.0], [0], [0], [0]]]\n",
      "bought products [[[8.0], [0], [0], [0]], [[4.0], [0], [0], [0]], [[12.0], [0], [0], [0]], [[15.0], [0], [0], [0]], [[3.0], [0], [0], [0]]]\n",
      "product 0\n",
      "arm: 0 , n_samples: 1\n",
      "cum_purchases:  4.0\n",
      "cum_clicks 8.0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 1 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 2 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 3 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "product 1\n",
      "arm: 0 , n_samples: 1\n",
      "cum_purchases:  4.0\n",
      "cum_clicks 6.0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 1 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 2 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 3 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "product 2\n",
      "arm: 0 , n_samples: 1\n",
      "cum_purchases:  4.0\n",
      "cum_clicks 5.0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 1 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 2 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 3 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "product 3\n",
      "arm: 0 , n_samples: 1\n",
      "cum_purchases:  5.0\n",
      "cum_clicks 7.0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 1 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 2 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 3 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "product 4\n",
      "arm: 0 , n_samples: 1\n",
      "cum_purchases:  3.0\n",
      "cum_clicks 3.0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 1 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 2 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "arm: 3 , n_samples: 0\n",
      "cum_purchases:  0\n",
      "cum_clicks 0\n",
      "beta_parameters [[[4. 4.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[4. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[5. 2.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[3. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\n\\ncum_purchases = [0 for j in range(5)]\\ncum_clicks = [0 for j in range(5)]\\ncum_bought_products = [0 for j in range(5)]\\n\\n# print(cum_purchases)\\n# print(cum_clicks)\\n# print(cum_bought_products)\\n\\n'"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swts_learner.pulled_arms = [np.array([]) for j in range(5)]\n",
    "swts_learner.clicks = [[[] for i in range(n_arms)] for j in range(5)]\n",
    "swts_learner.purchases = [[[] for i in range(n_arms)] for j in range(5)]\n",
    "swts_learner.n_bought_products =[[[] for i in range(n_arms)] for j in range(5)]\n",
    "swts_learner.beta_parameters = np.array([np.ones((n_arms, 2))] * 5)\n",
    "swts_learner.expected_rewards = np.zeros([5, n_arms])\n",
    "\n",
    "'''\n",
    "print(swts_learner.pulled_arms)\n",
    "print(swts_learner.clicks)\n",
    "print(swts_learner.purchases)\n",
    "print(swts_learner.n_bought_products)\n",
    "'''\n",
    "\n",
    "#print(pulled_arm)\n",
    "for i in range(5):\n",
    "    swts_learner.pulled_arms[i] = np.append(swts_learner.pulled_arms[i], pulled_arm[i])\n",
    "    for arm in range(n_arms):\n",
    "        if arm == int(pulled_arm[i]):\n",
    "            swts_learner.clicks[i][arm].append(env.clicks_current_day[i])\n",
    "            swts_learner.purchases[i][arm].append(env.purchases_current_day[i])\n",
    "            swts_learner.n_bought_products[i][arm].append(env.daily_units[i])\n",
    "        else:\n",
    "            swts_learner.clicks[i][arm].append(0)\n",
    "            swts_learner.purchases[i][arm].append(0)\n",
    "            swts_learner.n_bought_products[i][arm].append(0)\n",
    "\n",
    "print('clicks: ',swts_learner.clicks)\n",
    "print('purchases',swts_learner.purchases)\n",
    "print('bought products',swts_learner.n_bought_products)\n",
    "\n",
    "# cum_purchases = [[[0] for i in range(swts_learner.n_arms)] for j in range(5)]\n",
    "# cum_clicks = [[[0] for i in range(swts_learner.n_arms)] for j in range(5)]\n",
    "# n_bought_products = [[[0] for i in range(swts_learner.n_arms)] for j in range(5)]\n",
    "\n",
    "purchase = env.purchases_current_day\n",
    "click = env.clicks_current_day\n",
    "\n",
    "for i in range(5):\n",
    "    print('product',i)\n",
    "    for arm in range(swts_learner.n_arms):\n",
    "        n_samples = np.sum(swts_learner.pulled_arms[i][-swts_learner.window_size:] == arm)\n",
    "        print('arm:',arm, ', n_samples:', n_samples)\n",
    "        cum_purchases = np.sum(swts_learner.purchases[i][arm][-n_samples:])  if n_samples > 0 else 0\n",
    "        cum_clicks = np.sum(swts_learner.clicks[i][arm][-n_samples:]) if n_samples > 0 else 0\n",
    "        n_bought_products = np.sum(swts_learner.n_bought_products[i][arm][-n_samples:]) if n_samples > 0 else 0\n",
    "\n",
    "        swts_learner.beta_parameters[i][arm, 0] = cum_purchases if n_samples > 0 else 1\n",
    "        swts_learner.beta_parameters[i][arm, 1] = cum_clicks - cum_purchases if n_samples > 0 else 1\n",
    "\n",
    "        print('cum_purchases: ',cum_purchases)\n",
    "        print('cum_clicks',cum_clicks)\n",
    "        print('beta_parameters',swts_learner.beta_parameters)\n",
    "\n",
    "\n",
    "    #print('n_bought_products',n_bought_products)\n",
    "\n",
    "\n",
    "to_continue=0\n",
    "if to_continue:\n",
    "    pulled_arm = ts_learner.pull_arm(env.margins_matrix)\n",
    "    print(pulled_arm)\n",
    "    reward = env.round(pulled_arm)\n",
    "#swts_learner.update(pulled_arm, reward, env.clicks_current_day, env.purchases_current_day, env.daily_units)\n",
    "    swts_learner.t += 1\n",
    "    swts_learner.update_observations(pulled_arm, reward)\n",
    "    for i in range(5):\n",
    "        swts_learner.pulled_arms[i] = np.append(swts_learner.pulled_arms[i], pulled_arm[i])\n",
    "        for arm in range(n_arms):\n",
    "            if arm == int(pulled_arm[i]):\n",
    "                swts_learner.clicks[i][arm].append(env.clicks_current_day[i])\n",
    "                swts_learner.purchases[i][arm].append(env.purchases_current_day[i])\n",
    "                swts_learner.n_bought_products[i][arm].append(env.daily_units[i])\n",
    "            else:\n",
    "                swts_learner.clicks[i][arm].append(0)\n",
    "                swts_learner.purchases[i][arm].append(0)\n",
    "                swts_learner.n_bought_products[i][arm].append(0)\n",
    "\n",
    "\n",
    "    print(swts_learner.clicks)\n",
    "    print(swts_learner.purchases)\n",
    "    print(swts_learner.n_bought_products)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "cum_purchases = [0 for j in range(5)]\n",
    "cum_clicks = [0 for j in range(5)]\n",
    "cum_bought_products = [0 for j in range(5)]\n",
    "\n",
    "# print(cum_purchases)\n",
    "# print(cum_clicks)\n",
    "# print(cum_bought_products)\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SW-UCB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulation in a static environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------time  1\n",
      "pulled  [0 0 0 0 0]\n",
      "product  0\n",
      "arm 0 , n 0\n",
      "rewards till now:  [2.0]\n",
      "expected rewards [[2. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2. nan  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2. nan nan  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2. nan nan nan]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "product  1\n",
      "arm 0 , n 0\n",
      "rewards till now:  [4.0]\n",
      "expected rewards [[ 2. nan nan nan]\n",
      " [ 4.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2. nan nan nan]\n",
      " [ 4. nan  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2. nan nan nan]\n",
      " [ 4. nan nan  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2. nan nan nan]\n",
      " [ 4. nan nan nan]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "product  2\n",
      "arm 0 , n 0\n",
      "rewards till now:  [12.857142857142858]\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "product  3\n",
      "arm 0 , n 0\n",
      "rewards till now:  [21.333333333333332]\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan  0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "product  4\n",
      "arm 0 , n 0\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.          0.          0.          0.        ]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan  0.          0.        ]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan  0.        ]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "-----------time  2\n",
      "pulled  [1 1 1 1 1]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0]\n",
      "expected rewards [[ 2.                 nan         nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [8.0]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.                 nan         nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [2.6]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286         nan         nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [18.75]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "product  3\n",
      "arm 0 , n 1\n",
      "rewards till now:  [21.333333333333332]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333         nan         nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [21.0]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "product  4\n",
      "arm 0 , n 1\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.                 nan         nan         nan]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [7.666666666666667]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "-----------time  3\n",
      "pulled  [2 2 2 2 2]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0]\n",
      "expected rewards [[ 2.          8.                 nan         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [4.285714285714286]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [2.6]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6                nan         nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [3.5]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [18.75]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75               nan         nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "product  3\n",
      "arm 0 , n 1\n",
      "rewards till now:  [21.333333333333332]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [21.0]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.                 nan         nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [8.25]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "product  4\n",
      "arm 0 , n 1\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667         nan         nan]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [8.666666666666666]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  []\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "-----------time  4\n",
      "pulled  [3 3 3 3 3]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286]\n",
      "expected rewards [[ 2.          8.          4.28571429         nan]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [4.333333333333333]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [2.6]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5                nan]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [18.75]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.                 nan]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "product  3\n",
      "arm 0 , n 1\n",
      "rewards till now:  [21.333333333333332]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [21.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25               nan]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "product  4\n",
      "arm 0 , n 1\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667         nan]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [4.833333333333333]\n",
      "expected rewards [[ 2.          8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "-----------time  5\n",
      "pulled  [0 0 0 0 0]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.333333333333333]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 4.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [2.6]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [12.85714286 18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [18.75]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [21.33333333 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 1\n",
      "rewards till now:  [21.333333333333332, 19.2]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [21.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 1\n",
      "rewards till now:  [10.0, 10.0]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333]\n",
      "expected rewards [[ 1.2         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "-----------time  6\n",
      "pulled  [1 1 1 1 1]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.6         8.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0, 4.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.333333333333333]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.          2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         2.6         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [ 9.         18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 2\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 18.75       10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [18.75, 16.875]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [10.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [19.2        21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 2\n",
      "rewards till now:  [21.333333333333332, 19.2]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 21.          8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 2\n",
      "rewards till now:  [10.0, 10.0]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          7.66666667  8.66666667  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "-----------time  7\n",
      "pulled  [2 2 2 2 2]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.6         4.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0]\n",
      "expected rewards [[ 1.6         6.          4.28571429  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.333333333333333]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.9         3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        3.5         0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 2\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 16.875      10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [18.75, 16.875]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     10.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [10.0, 20.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 2\n",
      "rewards till now:  [21.333333333333332, 19.2]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 13.5         8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25        8.25        0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 2\n",
      "rewards till now:  [10.0, 10.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          3.83333333  8.66666667  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        8.66666667  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "-----------time  8\n",
      "pulled  [3 3 3 3 3]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0]\n",
      "expected rewards [[ 1.6         6.          3.33333333  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.6         6.          3.80952381  4.33333333]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.333333333333333, 5.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        1.75        0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       0.        ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 4.25]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 2\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [18.75, 16.875]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     20.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [10.0, 20.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 2\n",
      "rewards till now:  [21.333333333333332, 19.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       13.2         0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 2\n",
      "rewards till now:  [10.0, 10.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "-----------time  9\n",
      "pulled  [3. 3. 1. 0. 0.]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.2       ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       4.25      ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 4.25, 6.8]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 2\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 17.8125     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [18.75, 16.875, 13.5]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [10.0, 20.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [20.26666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 2\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 2\n",
      "rewards till now:  [10.0, 10.0, 10.0]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "-----------time  10\n",
      "pulled  [1. 3. 1. 0. 0.]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.6         6.          3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.85      ]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 3\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       5.525     ]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 3\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 2\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 15.1875     15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [10.0, 20.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.2        17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 3\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 3\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "-----------time  11\n",
      "pulled  [3. 3. 2. 0. 0.]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  5.34444444]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 3\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.5         3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.62777778]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 4\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [10.92857143 14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         14.41071429 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 15.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [10.0, 20.0, 18.0]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 3\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [10.          5.75        6.5         4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 3\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "-----------time  12\n",
      "pulled  [3. 3. 2. 0. 0.]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.2         5.6         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  7.15      ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 3 , n 4\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.25        2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [2.6, 3.9]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       4.00208333]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         15.49553571 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.          0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 2 , n 3\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.46666667 17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 4\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        17.25       10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [21.0, 13.5]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 8.88888889  5.75        6.5         4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 4\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  5.75        6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "-----------time  13\n",
      "pulled  [3. 1. 2. 1. 0.]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.2         4.4         3.80952381  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.175     ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          3.9         2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  2.625       3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        3.54166667]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 3 , n 6\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 19.33333333  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 2 , n 3\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.1        13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 5\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       13.5        10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [21.0, 13.5, 23.625]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      10.725       0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.16666667  3.83333333  6.5         4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 5\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  6.5         4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "-----------time  14\n",
      "pulled  [3. 1. 0. 1. 0.]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.24      ]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          4.33333333  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        2.95138889]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 9.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 12.66666667  0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 4\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 5\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.33333333  3.83333333  4.33333333  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 6\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.2         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "-----------time  15\n",
      "pulled  [3. 1. 1. 1. 0.]\n",
      "product  0\n",
      "arm 0 , n 0\n",
      "rewards till now:  [2.0, 1.2]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 2\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.06666667]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 6\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333, 8.666666666666666]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.          3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 0\n",
      "rewards till now:  [4.0, 3.0]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.46666667  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6, 4.642857142857143]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         14.41071429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858, 22.5]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 4\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.12       23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 4\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        23.625      13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625, 15.75]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 9.44444444  3.83333333  4.33333333  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 6\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0, 6.666666666666667]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "-----------time  16\n",
      "pulled  [0. 0. 1. 1. 0.]\n",
      "product  0\n",
      "arm 0 , n 0\n",
      "rewards till now:  [2.0, 1.2, 1.2]\n",
      "expected rewards [[ 1.46666667  4.4         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.5       ]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 7\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333, 8.666666666666666]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.5         3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 0\n",
      "rewards till now:  [4.0, 3.0, 2.6666666666666665]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6, 4.642857142857143]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         16.28571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858, 22.5, 18.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 4\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 4\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        21.         13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625, 15.75, 7.875]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25, 13.2]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 8.88888889  3.83333333  4.33333333  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 7\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0, 6.666666666666667, 10.0]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  3.83333333  4.33333333  4.83333333]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.46666667  4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "-----------time  17\n",
      "pulled  [0. 0. 1. 2. 1.]\n",
      "product  0\n",
      "arm 0 , n 1\n",
      "rewards till now:  [2.0, 1.2, 1.2, 2.0]\n",
      "expected rewards [[ 2.          4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 2.          4.8         3.33333333  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 7\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333, 8.666666666666666]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 3.22222222  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 1\n",
      "rewards till now:  [4.0, 3.0, 2.6666666666666665, 2.6666666666666665]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6, 4.642857142857143]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  1.75        3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [3.5, 1.75]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.78571429 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858, 22.5, 18.0, 16.071428571428573]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 14.5         0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 3\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 4\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        15.75       13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625, 15.75, 7.875]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [8.25, 13.2, 20.625]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.04761905  5.75        4.33333333  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 8\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0, 6.666666666666667, 10.0]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  5.75        4.33333333  4.83333333]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335, 7.666666666666667]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  4.33333333  4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 2.          4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "-----------time  18\n",
      "pulled  [2. 2. 1. 2. 2.]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2, 1.2, 2.0]\n",
      "expected rewards [[ 1.6         4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.6         4.8         3.80952381  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335, 8.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.31428571]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 3 , n 6\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333, 8.666666666666666]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0, 2.6666666666666665, 2.6666666666666665]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6, 4.642857142857143]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  2.625       3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [3.5, 1.75, 4.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.54166667]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 3 , n 4\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         17.35714286 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 1 , n 5\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858, 22.5, 18.0, 16.071428571428573, 15.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 2 , n 3\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 4\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625, 15.75, 7.875]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    14.025       0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.25, 13.2, 20.625, 13.2]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0, 0.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 8\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0, 6.666666666666667, 10.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  6.38888889  6.5         4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335, 7.666666666666667]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  6.5         4.83333333]]\n",
      "arm 2 , n 0\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333, 4.333333333333333]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "-----------time  19\n",
      "pulled  [2. 2. 3. 3. 2.]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2, 1.2, 2.0]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.6         4.8         5.20634921  6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335, 8.0, 7.5]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333, 8.666666666666666]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0, 2.6666666666666665, 2.6666666666666665]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6, 4.642857142857143]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  3.08333333  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [3.5, 1.75, 4.0, 4.666666666666667]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  3.36458333]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 3 , n 3\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 1 , n 5\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858, 22.5, 18.0, 16.071428571428573, 15.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 2 , n 3\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  0.        ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0, 0.0, 7.875]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.1        17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 3\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625, 15.75, 7.875]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    13.2         0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2, 20.625, 13.2]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      0.        ]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [0.0, 0.0, 29.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.16666667  7.66666667  5.77777778  4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 7\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0, 6.666666666666667, 10.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667  5.77777778  4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335, 7.666666666666667]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667  5.77777778  4.83333333]]\n",
      "arm 2 , n 1\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333, 4.333333333333333, 13.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "-----------time  20\n",
      "pulled  [2. 2. 3. 3. 3.]\n",
      "product  0\n",
      "arm 0 , n 2\n",
      "rewards till now:  [2.0, 1.2, 1.2, 2.0]\n",
      "expected rewards [[ 1.6         4.8         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 1 , n 0\n",
      "rewards till now:  [8.0, 4.0, 4.8]\n",
      "expected rewards [[ 1.6         5.6         7.5         6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [4.285714285714286, 3.3333333333333335, 8.0, 7.5, 5.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 3 , n 5\n",
      "rewards till now:  [4.333333333333333, 5.2, 6.5, 9.75, 3.25, 6.5, 4.333333333333333, 8.666666666666666]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "product  1\n",
      "arm 0 , n 2\n",
      "rewards till now:  [4.0, 3.0, 2.6666666666666665, 2.6666666666666665]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 1 , n 3\n",
      "rewards till now:  [2.6, 3.9, 4.333333333333333, 2.6, 4.642857142857143]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.66666667  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [3.5, 1.75, 4.0, 4.666666666666667, 3.5]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  2.21944444]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 3 , n 2\n",
      "rewards till now:  [0.0, 4.25, 6.8, 2.8333333333333335, 2.125, 1.7]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "product  2\n",
      "arm 0 , n 1\n",
      "rewards till now:  [12.857142857142858, 9.0, 6.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         16.88571429 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [18.75, 16.875, 13.5, 12.857142857142858, 22.5, 18.0, 16.071428571428573, 15.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 2 , n 3\n",
      "rewards till now:  [10.0, 20.0, 18.0, 20.0, 0.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667  2.625     ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0, 7.875, 10.5]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [19.06666667 17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "product  3\n",
      "arm 0 , n 2\n",
      "rewards till now:  [21.333333333333332, 19.2, 19.2, 20.0, 19.2, 18.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 1 , n 4\n",
      "rewards till now:  [21.0, 13.5, 23.625, 23.625, 15.75, 7.875]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.25, 13.2, 20.625, 13.2]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125      9.66666667]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "arm 3 , n 1\n",
      "rewards till now:  [0.0, 0.0, 29.0, 10.875]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125     10.875     ]\n",
      " [ 9.04761905  7.66666667 13.          4.83333333]]\n",
      "product  4\n",
      "arm 0 , n 6\n",
      "rewards till now:  [10.0, 10.0, 10.0, 10.0, 6.666666666666667, 10.0, 10.0, 10.0, 6.666666666666667, 10.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125     10.875     ]\n",
      " [ 8.88888889  7.66666667 13.          4.83333333]]\n",
      "arm 1 , n 1\n",
      "rewards till now:  [7.666666666666667, 3.8333333333333335, 7.666666666666667]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125     10.875     ]\n",
      " [ 8.88888889  7.66666667 13.          4.83333333]]\n",
      "arm 2 , n 2\n",
      "rewards till now:  [8.666666666666666, 4.333333333333333, 4.333333333333333, 13.0]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125     10.875     ]\n",
      " [ 8.88888889  7.66666667  8.66666667  4.83333333]]\n",
      "arm 3 , n 0\n",
      "rewards till now:  [4.833333333333333, 4.833333333333333, 4.833333333333333]\n",
      "expected rewards [[ 1.6         5.6         6.25        6.5       ]\n",
      " [ 2.66666667  3.85873016  4.08333333  1.9125    ]\n",
      " [ 6.         17.89285714 12.66666667 10.5       ]\n",
      " [18.6        17.71875    16.9125     10.875     ]\n",
      " [ 8.88888889  7.66666667  8.66666667  4.83333333]]\n"
     ]
    }
   ],
   "source": [
    "#Comparison between SW-UCB and UCB\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 20\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "sw_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "sw_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    sw_UCB_learner = SW_UCB(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = sw_UCB_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm, )\n",
    "        sw_UCB_learner.update(pulled_arm, reward)\n",
    "\n",
    "    sw_ucb_rewards_per_experiment.append(sw_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    sw_ucb_pulls_per_arm_per_experiment.append(sw_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt - sw_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(opt - ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"SW UCB\",\"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Come previsto, SW UCB si comporta peggio di UCB (in un AMBIENTE STATICO)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation in a changing environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------time  1\n",
      "pulled  [0 0 0 0 0]\n",
      "-----------time  2\n",
      "pulled  [1 1 1 1 1]\n",
      "-----------time  3\n",
      "pulled  [2 2 2 2 2]\n",
      "-----------time  4\n",
      "pulled  [3 3 3 3 3]\n",
      "-----------time  5\n",
      "pulled  [0 0 0 0 0]\n",
      "-----------time  6\n",
      "pulled  [1 1 1 1 1]\n",
      "-----------time  7\n",
      "pulled  [2 2 2 2 2]\n",
      "-----------time  8\n",
      "pulled  [3 3 3 3 3]\n",
      "-----------time  9\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  10\n",
      "pulled  [3. 3. 1. 3. 3.]\n",
      "-----------time  11\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  12\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  13\n",
      "pulled  [2. 3. 2. 3. 3.]\n",
      "-----------time  14\n",
      "pulled  [2. 3. 2. 2. 0.]\n",
      "-----------time  15\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  16\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  17\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  18\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  19\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  20\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  21\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  22\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  23\n",
      "pulled  [1. 3. 2. 1. 3.]\n",
      "-----------time  24\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  25\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  26\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  27\n",
      "pulled  [3. 3. 0. 3. 3.]\n",
      "-----------time  28\n",
      "pulled  [3. 3. 0. 2. 3.]\n",
      "-----------time  29\n",
      "pulled  [3. 3. 1. 2. 3.]\n",
      "-----------time  30\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  31\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  32\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  33\n",
      "pulled  [1. 3. 2. 1. 3.]\n",
      "-----------time  34\n",
      "pulled  [1. 3. 2. 1. 3.]\n",
      "-----------time  35\n",
      "pulled  [2. 3. 2. 1. 3.]\n",
      "-----------time  36\n",
      "pulled  [2. 3. 2. 0. 3.]\n",
      "-----------time  37\n",
      "pulled  [2. 3. 2. 0. 3.]\n",
      "-----------time  38\n",
      "pulled  [2. 3. 2. 2. 3.]\n",
      "-----------time  39\n",
      "pulled  [2. 3. 2. 3. 3.]\n",
      "-----------time  40\n",
      "pulled  [2. 3. 2. 2. 3.]\n",
      "-----------time  41\n",
      "pulled  [2. 3. 2. 2. 3.]\n",
      "-----------time  42\n",
      "pulled  [2. 3. 2. 1. 3.]\n",
      "-----------time  43\n",
      "pulled  [3. 3. 1. 1. 3.]\n",
      "-----------time  44\n",
      "pulled  [3. 3. 1. 1. 3.]\n",
      "-----------time  45\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  46\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  47\n",
      "pulled  [3. 3. 2. 1. 3.]\n",
      "-----------time  48\n",
      "pulled  [2. 3. 2. 1. 2.]\n",
      "-----------time  49\n",
      "pulled  [2. 3. 2. 1. 3.]\n",
      "-----------time  50\n",
      "pulled  [2. 3. 2. 1. 3.]\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [ 74.30083707 148.60167414 222.90251121 297.20334828 371.50418534]\n",
      "-----------time  51\n",
      "pulled  [2. 3. 2. 1. 0.]\n",
      "-----------time  52\n",
      "pulled  [2. 3. 0. 2. 3.]\n",
      "-----------time "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucamainini/opt/anaconda3/envs/math_environment/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/lucamainini/opt/anaconda3/envs/math_environment/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53\n",
      "pulled  [2. 3. 2. 2. 3.]\n",
      "-----------time  54\n",
      "pulled  [1. 3. 2. 2. 3.]\n",
      "-----------time  55\n",
      "pulled  [3. 3. 2. 2. 3.]\n",
      "-----------time  56\n",
      "pulled  [0. 0. 2. 2. 3.]\n",
      "-----------time  57\n",
      "pulled  [0. 1. 2. 2. 1.]\n",
      "-----------time  58\n",
      "pulled  [3. 2. 2. 0. 1.]\n",
      "-----------time  59\n",
      "pulled  [1. 2. 3. 0. 3.]\n",
      "-----------time  60\n",
      "pulled  [3. 3. 3. 0. 1.]\n",
      "-----------time  61\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  62\n",
      "pulled  [3. 3. 3. 1. 1.]\n",
      "-----------time  63\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  64\n",
      "pulled  [3. 3. 3. 1. 3.]\n",
      "-----------time  65\n",
      "pulled  [2. 3. 3. 2. 3.]\n",
      "-----------time  66\n",
      "pulled  [2. 3. 3. 1. 3.]\n",
      "-----------time  67\n",
      "pulled  [2. 3. 3. 2. 3.]\n",
      "-----------time  68\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  69\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  70\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [ 89.16100448 178.32200897 267.48301345 356.64401793 445.80502241]\n",
      "-----------time  71\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  72\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  73\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  74\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  75\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  76\n",
      "pulled  [3. 3. 3. 2. 3.]\n",
      "-----------time  77\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  78\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  79\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  80\n",
      "pulled  [3. 3. 1. 2. 1.]\n",
      "-----------time  81\n",
      "pulled  [3. 3. 0. 2. 1.]\n",
      "-----------time  82\n",
      "pulled  [3. 3. 0. 2. 1.]\n",
      "-----------time  83\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  84\n",
      "pulled  [2. 3. 3. 2. 1.]\n",
      "-----------time  85\n",
      "pulled  [3. 3. 3. 2. 1.]\n",
      "-----------time  86\n",
      "pulled  [1. 3. 3. 2. 3.]\n",
      "-----------time  87\n",
      "pulled  [2. 3. 3. 0. 1.]\n",
      "-----------time  88\n",
      "pulled  [2. 3. 2. 2. 3.]\n",
      "-----------time  89\n",
      "pulled  [3. 3. 2. 2. 1.]\n",
      "-----------time  90\n",
      "pulled  [3. 3. 2. 3. 1.]\n",
      "-----------time  91\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  92\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  93\n",
      "pulled  [3. 3. 2. 3. 3.]\n",
      "-----------time  94\n",
      "pulled  [3. 3. 2. 2. 1.]\n",
      "-----------time  95\n",
      "pulled  [3. 3. 1. 3. 1.]\n",
      "-----------time  96\n",
      "pulled  [3. 3. 1. 2. 3.]\n",
      "-----------time  97\n",
      "pulled  [3. 3. 1. 3. 1.]\n",
      "-----------time  98\n",
      "pulled  [3. 3. 1. 2. 1.]\n",
      "-----------time  99\n",
      "pulled  [3. 3. 1. 2. 2.]\n",
      "-----------time  100\n",
      "pulled  [3. 3. 1. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#Comparison between SW-UCB and UCB\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 100\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "days_of_change = [50, 70]\n",
    "\n",
    "window_size = 50\n",
    "\n",
    "sw_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "sw_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    sw_UCB_learner = SW_UCB(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "        for day_of_change in days_of_change:\n",
    "            if d==day_of_change:\n",
    "                env.abrupt_change([0],1.20)\n",
    "\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = sw_UCB_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm, )\n",
    "        sw_UCB_learner.update(pulled_arm, reward)\n",
    "\n",
    "    sw_ucb_rewards_per_experiment.append(sw_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    sw_ucb_pulls_per_arm_per_experiment.append(sw_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3AElEQVR4nO3deZzN9f7A8dc72Vq0oK5QJNkZmWRpkVQqpftrodtCKYVuKXJpVTeprlvaVBMVqaS6ZSkVE5F97FsyiIYJSdYwy/v3x/tLB7PRnHNm5ryfj8c8zvd8zvd7zuc7OG+f7f0RVcU555zLyVHRroBzzrmCz4OFc865XHmwcM45lysPFs4553LlwcI551yuPFg455zL1dHhemMRqQF8FFJ0JvA4MCworwL8BNyoqluCa/oAnYAM4D5V/ToobwS8C5QGvgTu11zm/JYrV06rVKmSb/fjnHOxYM6cOb+qavmDyyUS6yxEpBiwDjgP6Ab8pqrPikhv4CRV/ZeI1AY+BBoDpwETgLNVNUNEZgH3AzOwYPGyqo7L6TPj4+M1KSkpfDflnHNFkIjMUdX4g8sj1Q11CbBSVdcAbYGhQflQ4NrguC0wQlX3qOpqIBloLCIVgDKqOj1oTQwLucY551wERCpYtMdaDQCnqmoqQPB4SlBeEfg55JqUoKxicHxwuXPOuQgJe7AQkRLANcDHuZ2aRZnmUJ7VZ3UWkSQRSdq0adPhVdQ551y2wjbAHeIKYK6qbgiebxCRCqqaGnQxbQzKU4DKIddVAtYH5ZWyKD+EqiYACWBjFge/npaWRkpKCrt37/4r9xMTSpUqRaVKlShevHi0q+KcKwAiESxu4s8uKIDRQAfg2eBxVEj5ByLyAjbAXR2YFQxwbxeRJsBM4DbglSOpSEpKCscffzxVqlRBJKsGiwNQVTZv3kxKSgpVq1aNdnWccwVAWLuhROQY4FLgfyHFzwKXisiK4LVnAVR1CTASWAp8BXRT1Yzgmi7AYGzQeyWQ40yo7OzevZuyZct6oMiFiFC2bFlvgTnn9gtry0JVdwFlDyrbjM2Oyur8fkC/LMqTgLr5UScPFHnjvyfnXChfwe2cc0XF0qXw8MMQhvVzHiwirF+/ftSpU4f69esTFxfHzJkzGTVqFNdee+3+c/r3789ZZ521//mYMWO45pprDnmvKlWq8Ouvv+5/PmnSJNq0abP/+bhx44iPj6dWrVrUrFmTnj17AtC3b18qVqxIXFwcNWvWpEuXLmRmZobhbp1zEZGZCS++COecA2+9BSkpuV9zmDxYRND06dMZO3Ysc+fOZeHChUyYMIHKlSvTrFkzpk+ffsB5ZcqUYeNGmyg2bdo0mjdvfliftXjxYu69916GDx/OsmXLWLx4MWeeeeb+1x944AHmz5/P0qVLWbRoEd99913+3KRzLrLWrIFWreDBB+Gyy2DxYqhcOffrDpMHiwhKTU2lXLlylCxZEoBy5cpx2mmnUb58eU444QSSk5MBWLduHddddx3Tpk0DLFg0a9bssD7r+eef55FHHqFmzZoAHH300XTt2vWQ8/bu3cvu3bs56aST/sqtOeciTRUSEqBePZg9G4YMgVGj4NRTw/JxkZg6WzB17w7z5+fve8bFwcCB2b582WWX8dRTT3H22WfTqlUr2rVrx0UXXQRAs2bNmDZtGhkZGVSvXp0mTZrw9ddf06ZNGxYuXMi55557WFVZvHgxPXr0yPb1F198keHDh7NmzRquuOIK4uLiDuv9nXNRtGYN3HknTJgALVtaoAhz4lRvWUTQcccdx5w5c0hISKB8+fK0a9eOd999F4DmzZszbdo0pk2bRtOmTWncuDEzZ85k3rx51KhRg1KlSh3yflnNWMrrLKZ93VAbN25k586djBgx4i/dm3MuAlThzTehbl2YMQNef90CRgQybMduyyKHFkA4FStWjBYtWtCiRQvq1avH0KFD6dixI82aNeOVV14hIyODu+66i+OPP57du3czadKkbMcrypYty5YtWyhXrhwAv/322/7jOnXqMGfOHBo0aJBjfYoXL07r1q2ZPHky7du3z9+bdc7ln5Ur4e67ITERLrkEBg8+JEj88gt89hl06ZL/H+8tiwhavnw5K1as2P98/vz5nHHGGQDUrl2b9evXM2XKFBo2bAhAXFwcb7zxRrbjFS1atOC9994DICMjg+HDh3PxxRcD8NBDD/HMM8/w448/ApCZmckLL7xwyHuoKtOmTaNatWr5d6POufyzfDl07Ag1asDMmfDGGzB+/CGB4ssvoX596NED1q7N/2p4sIigHTt20KFDB2rXrk39+vVZunQpffv2Baz76LzzzqNcuXL78zE1bdqUVatWZRssHnvsMZKTk2nQoAENGzbkrLPO4pZbbgGgfv36DBw4kJtuuolatWpRt25dUlNT91/74osvEhcXR926dUlPT89y8Ns5F0WbNsFtt0GtWjByJNx7L/zwg7UuQrqbd++G+++Hq66CChUgKQlOPz3/qxORzY+iIavNj5YtW0atWrWiVKPCx39fzkWBKnz4oUWArVvhgQesuXDKKYecOmeOxZOlS23OTv/+kMXw5mGJ9uZHzjnncrNuHVxzDdx8M1SrBvPmwXPPHRIo0tLgySehSRP4/Xf46itbk/dXA0VOYneA2znnCgpVGDrUmgd798ILL8B990GxYoecmpICN94I06dbTHnlFYjEMikPFs45F00pKTYO8eWXcMEF8PbbEJLuJ1RiIrRvb+MUI0ZAu3aRq6Z3QznnXDSo2vTXOnVg0iR46SV7zCJQ7N4Njz9u2TxOOcUWbEcyUIC3LJxzLrL27IHRo+HVV2HyZGjRwoJGNtPXJ0yArl1hxQq49VYYNAiOOy6yVQZvWTjnXGT8/rsl+zvtNBt0WLnSVmAnJmYZKLZssZlOl15qSWW//hqGDYtOoAAPFhH3008/Ubfugfs49e3blwEDBgAwYMAAatasSd26dWnQoAHDhg0DbAFejRo1iIuLo1atWiQkJES87s65IzRqFNSuDS+/bH1JX39t+Z3uuQeOOvRr+OuvLaPHhx/Co49aItnLLotCvUN4N1QB8sYbbzB+/HhmzZpFmTJl2Lp1K59//vn+199//33i4+P57bffqFatGh07dqREiRLRq7BzLme//QbdutlodIMGMHas7TmRjT/+gJ49raupdm3rrWrUKIL1zYEHiwLkmWeeYeLEiZQpUwaAE044gQ4dOhxy3o4dOzj22GMplsW0OudcAfHtt9aPtHEjPPUU9O4NQXaGrPzwgw1aL1xovVX9+oV33cThitlgEYUM5Tn6448/2L59e445mm6++WZKlizJihUrGDhwoAcL5wqivXut72jAADj7bOuCyqF5kJkJ77xjC7ZLl7YZtFdcEcH65pGPWURYdinEMzMzc00v/v7777Nw4ULWrl3LgAEDWLNmTTiq6Jw7UsuWwXnnwX/+A3fdZfk4sgkUqvDFF9CwoW1NER9v/4EtiIECwtyyEJETgcFAXUCBO4DlwEdAFeAn4EZV3RKc3wfoBGQA96nq10F5I+BdoDTwJXC//sWkVlHKUL4/rXio3377jUaNGnHssceyatWqA7Y/zUr58uU555xzmDlz5v6stc65KFK1gYaePW260uefQ9u22Z4+Z46lfJoyxSZCffCBdUFlMdZdYIS7ai8BX6lqTaABsAzoDSSqanUgMXiOiNQG2gN1gNbAIBHZ18/yOtAZqB78tA5zvcPmuOOOo0KFCiQmJgIWKL766ivOP/98+vTpQ7du3di2bRsA27Zty3LW065du5g3b56nFXeuIFi92ua33nuvrZlYtCjbQLFxo7Uizj3XMo8PGmSNkZtuKtiBAsLYshCRMsCFQEcAVd0L7BWRtkCL4LShwCTgX0BbYISq7gFWi0gy0FhEfgLKqOr04H2HAdcC48JV93AbNmwY3bp127/t6RNPPEG1atXo0qULO3bs4Nxzz6V48eIUL178gK1Rb775ZkqXLs2ePXvo2LEjjQrKNAnnYlFmpn3b9+5t3/Svv35I+vB9VG2NxP33w86d1qp4/HE44YQo1PsIhbMb6kxgE/COiDQA5gD3A6eqaiqAqqaKyL50ihWBGSHXpwRlacHxweWHEJHOWAuE08OR0D2f1K5dm4kTJx5SLiL06tWLXr16HfLapEmTIlAz51yerF1rGxJNnAiXXw4JCdluIvHLL9C5M4wZA+efD2+9BTVrRra6+SGcDZ+jgXOA11W1IbCToMspG1mN7moO5YcWqiaoaryqxpcvX/5w6+ucczlTheHDoV49S9A0eDCMG5dloMjMtJyAderYxnb//a+lfiqMgQLCGyxSgBRVnRk8/wQLHhtEpAJA8Lgx5PzKIddXAtYH5ZWyKHfOuchZvNimKt16qwWLBQugU6csu52WLIGLLrKXa9e2bSkefDDLjOOFRtiChar+AvwsIjWCokuApcBoYN9Ksw7AqOB4NNBeREqKSFVsIHtW0GW1XUSaiM0tvS3kmiOp15FeGlP89+RcYONGS8vRoIHtgf3ii/Ddd5DFrMW9e6FvX1tztXQpDBlipxbW1kSocC/K+yfwvoiUAFYBt2MBaqSIdALWAjcAqOoSERmJBZR0oJuqZgTv04U/p86O4wgHt0uVKsXmzZspW7ZsrmsaYpmqsnnzZkoVpOWjzkVaWpplhn3ySRuVvvdeG5UuWzbL0+fOhdtvtxXY//iHTc8vSr3hMbUHd1paGikpKezevTtKtSo8SpUqRaVKlSieQ3oC54qsCRNsp7ply6B1a2tNZNM82LbN4slLL9leE2+8YTujFlbZ7cEdU+k+ihcvTtWqVaNdDedcQZWaaoMLI0bYarkxY+Cqq7KdDvvBB7YOb8MGWz/x3HOR2eI0GmIqWDjnXJYyM22dxMMP27Z0Tzxh6yey6Yr97Te44w5L+xQfb4+NG0e4zhHmwcI5F9uWL7dmwfffQ6tWttCuevVsT5861VZc//ILvPCC9VYV5llOeVXAF5g751yYbN5sLYgGDWxa7DvvwDffZBso0tJsptNFF0GJEjBtmq3EjoVAAd6ycM7FmnXrLH14QgLs2gXXX2872FWokO0lS5fa1hRz5sDNN1vjI9h2JmZ4y8I5FxtUbeFDzZrwyitw3XWW9O/jj7MNFLt32yZE55xju6B+8okt4I61QAHesnDOxYLUVNtf4osvLDPs4ME22ykbqjZo/eCDllT2uuvgtdfg1FMjV+WCxlsWzrmiKyPDZjnVrg2JibZSLjExx0CxZYsFh7//HY45xk7/5JPYDhTgLQvnXFE1axZ07WoDDS1b2kBDjRo5XjJ7Ntx4I6SkwPPP2wD20f4tCXjLwjlX1Pz8syX7O+88634aMcJWZOcQKFQts0fz5rbkYsoUeOghDxSh/FfhnCsa9uyBZ56x/a8zM22BXe/ecPzxOV62Y4cNZ4wYYYu1hw2Dk0+OUJ0LEQ8WzrnCb948m9u6eDG0bw/PPgt52J9+yRK44QZbl9ev35+b3rlD+a/FOVd4ZWTA009bro3Nm22204cf5hooUlOhSxdbj7dpE3z9tTVEPFBkz1sWzrnCacsWywX+1VfWmnjttVz7j7Zvt16q//7X9p645x547DGf6ZQXHiycc4XPwoU2t/Xnn+HNN22T6xykp9sWp48/bhlib7zRup3OOitC9S0CPFg45woPVXjrLZvTesIJtg1d06Y5XrJsmSX+W7AAzj/fFtudd16E6luEeA+dc65w2LDBdhW6+24LEHPm5BgoVK01ER8P69dbVo/Jkz1QHCkPFs65gm3nTtuprm5dGD/eVmF/802Oif+2boVbboFOnaBJE5g/3/IF+m7KR867oZxzBdOuXbZX6QsvwK+/Wk6n116z1B05mDrVAsXPP8O//w19+sROGvFw8paFc67gmTgR6tWz+ayNG1sEmDgxx0CxZ49tT3HhhdaCmDIFHn3UA0V+CWuwEJGfRGSRiMwXkaSg7GQRGS8iK4LHk0LO7yMiySKyXEQuDylvFLxPsoi8LOKNSeeKpO3bbQFEy5b2jT9xoq2daNYsx8vGjoU6deCpp2w27fz5uY57u8MUiZbFxaoap6rxwfPeQKKqVgcSg+eISG2gPVAHaA0MEpF9/yd4HegMVA9+Wkeg3s65SEpMtNZEQgL06GHTY1u0yPGS5GRo0wauvhqKF7fFde+9F5v7TYRbNLqh2gJDg+OhwLUh5SNUdY+qrgaSgcYiUgEoo6rTVVWBYSHXOOcKu507oVs32/+6ZEnbC3vAAMsPnsMljzxirYnJk+30BQvgsssiWO8YE+4BbgW+EREF3lTVBOBUVU0FUNVUETklOLciMCPk2pSgLC04PrjcOVfY/fAD/N//2eODD1rqjtKlsz1dFT791JZZpKRYctnnnstxYpTLJ+EOFs1VdX0QEMaLyA85nJvVOITmUH7oG4h0xrqrOP300w+3rs65SBo50ua2li5tU2IvuSTH05cvh3/+005t0MBSQJ1/foTq6sLbDaWq64PHjcBnQGNgQ9C1RPC4MTg9BagccnklYH1QXimL8qw+L0FV41U1vnz58vl5K865/LJxowWJdu1s7cTcuTkGij/+sPxN9erBzJnw8suQlOSBItLCFixE5FgROX7fMXAZsBgYDXQITusAjAqORwPtRaSkiFTFBrJnBV1W20WkSTAL6raQa5xzhUVami2oO/ts2zSiVy9L11GpUraXjB9vQeLppy2f048/WuvCNyWKvHD+yk8FPgtmuR4NfKCqX4nIbGCkiHQC1gI3AKjqEhEZCSwF0oFuqpoRvFcX4F2gNDAu+HHOFRZff20DDcuWweWXW9CoWTPb09euhZ49LUXH2WfbRKmWLSNXXXcosQlGRU98fLwmJSVFuxrOxbbkZOje3dZKnHWW5Qa/+ups827s3m0pxPv3t+d9+lgDpGTJyFU51onInJClDvt5Y845Fx5ffmnpXsEiwD//me23viqMGWNxZfVq271uwADweSoFh6f7cM7lL1ULDm3aQLVqsGiR9SllEyhWrYIrr4S2bW1iVGKiTZTyQFGweLBwzuWffbvX9eplaV6nTMn2W18VhgyxabBTp1pi2fnzfWyioPJuKOdc/vjqK5sSu2GDbUPXp0+2YxObNtnmdp9/DhdfDO++6y2Jgs5bFs65v2bnTkv+d8UVcOKJthji4YezDRTffmutiS+/tHGJCRM8UBQGHiycc0du3jxo1Mj2we7Z03ava9Qoy1PT0iyfU6tWluhv5kzLF3iUfwsVCv7H5Jw7fKq2KdF551la8QkTbFC7VKksT1++3FZcP/MM3H67xZS4uMhW2f01Hiycc4dn2zYbvO7RA666ylKJZzMqnZlp6Tni4mzJxUcf2aD2scdGtsrur/MBbudc3i1dallik5Ntgd0DD2Q7NrFiBdx1l2X0uPJKGDzYs8MWZt6ycM7lzQcf2Banv/9uo9QPPphloEhLg2eftZxO8+dbkBg71gNFYefBwjmXs9274Z574OaboWFDyxJ74YVZnjp/vsWTPn1sTd6yZTab1jdCLvw8WDjnsjd3ru1//eab8K9/2Z7Yp512yGl798ITT8C550Jqqm1Q9Mkn3pooSnzMwjl3qK1b4dFHYdAgKF8eRo+2BIBZWLjQdqxbuBBuucUSypYtG9nquvDzloVz7k+7dtm3fY0aFii6drUtT7MIFOnplh02Pt4WbY8eDe+954GiqPKWhXPORqVfeQWef96++S+6yNKKZ7PAbulSG4uYMcNm0b7+OpQrF+E6u4jyYOFcrFu3zrY4nTrVtjcdOTLbAey9ey2e/PvfcNxxMHy45Q30Aeyiz4OFc7FswgT7tt+1y6bG7tt/IgvTp8Pdd1vG8XbtbLHdKadEsK4uqnzMwrlYlJZmA9iXXWYD2LNnZxsotmyxINGsmR2PGgUjRnigiDUeLJyLNcnJlqipXz/o0AFmzYJatQ45LTMT3nnHxrqHDLHsHsuWwTXXRKHOLuo8WDgXK/btNtSwIfz4o41NvPNOloma5syxlsQdd0D16pCUZOnEjzsuCvV2BULYg4WIFBOReSIyNnh+soiMF5EVweNJIef2EZFkEVkuIpeHlDcSkUXBay+L+HCac4dlwwbbt/TOO22u64IFttH1Qdats6yw554LP/0EQ4fC9997hlgXmZbF/cCykOe9gURVrQ4kBs8RkdpAe6AO0BoYJCLFgmteBzoD1YOf1hGot3NFw6hRULcufPON7V2amHjIbkM7d0LfvnD22TbO3aOHpRW/7Taf6eRMnoKFiNwvImXEDBGRuSJyWR6uqwRcBQwOKW4LDA2OhwLXhpSPUNU9qroaSAYai0gFoIyqTldVBYaFXOOcy86uXbaD3bXXWnCYOxe6dz9gt6HMTFtId/bZ8OSTls/phx9sa4oTTohazV0BlNeWxR2qug24DCgP3A48m4frBgK9gMyQslNVNRUgeNw3p6Ii8HPIeSlBWcXg+OBy51x2Zsyw7qY33oCHHrJ5r7VrH3DKnDnQtKm1HipWtGUWH30EVatGqc6uQMtrsNjXEL0SeEdVF4SUZX2BSBtgo6rOOczPCKU5lGf1mZ1FJElEkjZt2pTHj3WuCPnhB9tvomlTy+80frytoitRYv8pO3ZYdvHGjeHnn2HYMIstzZpFsd6uwMtrsJgjIt9gweJrETmeA1sLWWkOXCMiPwEjgJYiMhzYEHQtETxuDM5PASqHXF8JWB+UV8qi/BCqmqCq8aoaX758+TzemnNFwLZt8M9/Qp06ttDuqads0KFVqwNOS0y0U1580dZOLFtmSQB9H2yXm7z+FemEDUSfq6q7gBJYV1S2VLWPqlZS1SrYwPW3qnoLMBroEJzWARgVHI8G2otISRGpig1kzwq6qraLSJNgFtRtIdc458aOtQjw2ms2RrFyJTz22AHzXPfsgZ49LXYcc4zNcBo0yMclXN7lmO5DRM45qOjMfJi1+iwwUkQ6AWuBGwBUdYmIjASWAulAN1XNCK7pArwLlAbGBT/OxbaUFOtP+vhjCxYffwxNmhxy2vz50LGjzZbt2tUGr485JuK1dYWc2ASjbF4UmRgclgIaAQuxMYT6wExVPT/sNTxC8fHxmpSUFO1qOJf/0tIsjfiTT0JGBjzyCPTqdcC4BMBvv1lGjzfftIywQ4bYbCfnciIic1Q1/uDyHLuhVPViVb0YWAM0CsYDGgENsamtzrlIUYUxY6B+fQsOF19sucIfffSAQJGZaften322BYp777XhCw8U7q/I65hFTVVdtO+Jqi4G4sJSI+fcoebPt/Th11xj0WDUKAscB81zXbzYsovfdZfNlJ03D156CU48MSq1dkVIXoPFDyIyWERaiMhFIvIWB67Kds6FQ3o6PP205d9YtAhefdUiwkHZ/LZvt8ZGw4Y2e/btt+G776wR4lx+yOt+Fh2xQeb7g+eTsRQczrlwSU62ea0zZtieE6++CieddMApqpYuvGdPWL/e8jo9/7zvWufyX67BIsjPNFZVWwEvhr9KzsW4zMw/V16XKAEffgjt2x9y2pQp0KePrbw+5xz49NMsJ0M5ly9y7YYKpq/uEhGfke1cuK1ZYxsSdesGF1xgXU8HBYp58+CKK2xsYtUqG8SeNcsDhQuvvHZD7QYWich4YOe+QlW9Lyy1ci7WpKfDK6/A44/b84QESycesq4pNdVmyb77rvVG/ec/FlNKl45OlV1syWuw+CL4cc7lt2nTbOX1woVw5ZU2NhEyy2nXLkvP0b8/7N1r6cMfecRnOLnIylOwUNWhuZ/lnDssu3bBww/Dyy9DpUrw2We2QVHQmsjMhPfft1NSUuDvf7fWRLVqUa63i0l5ChYiUh3oD9TGVnMDoKpnhqlezhVtU6daDo7kZFs117//AbmcJk+2FkRSEjRqZEHjwgujV13n8rrO4h1sqmw6cDG2AdF74aqUc0XW5s3QubMNXqenw8SJNlYRBIrkZLjuOrjoIvjlF0sfPmuWBwoXfXkNFqVVNRHLJbVGVfsCLcNXLeeKmH05OGrUsBVzDzxgYxQtWux/eeBA2/30669tHd7y5Z4+3BUceZ4NJSJHAStE5F5gHX/ucOecy8maNXDHHfDtt9ZEeO01iwqBtWttMd2338LVV9tU2AoVolhf57KQ1/+zdAeOAe7Dss/ewp97UjjnsqJqrYl69WD2bHjrLZg0aX+gUIXhwy0lx6xZduqoUR4oXMGU15bFZlXdAewgl02PnHPY9KU777Q+pZYtrevpjDP2v7x5M9xzD3zyCTRvbmMTZ/p0EVeA5bVl8a6IrBSRESLSVUTqhbVWzhVWqhYY6tSxfByvvmr7YAeBYts2m/5ap461Ivr3t4R/HihcQZfXdRYXikgJ4FygBfCFiBynqieHs3LOFSobN1prYswYm8709tv7o8COHdCvn21lum2bNTb++1+Ii4tulZ3Lq7yuszgfuCD4OREYC0wJX7WcK2S++MIGsbduteXW9923fxrTzJlw882Wx+n66y2VePwh+5A5V7DldcziOyAJW5j3paruDV+VnCtE/vjDssO+9pqNVCcm7h/Azsiw1sRTT0HFija27eslXGGV12BRFmgOXAjcJyKZwHRVfSxsNXOuoFuyxDLCLl4MDz4IzzwDJUsCtqDuppssQNx8sw1deC4nV5jldczidxFZBVQGKgHNgOLhrJhzBVZamuVzevRRKFMGxo2D1q33vzxpkgWKrVvhnXcsq4dzhV2eZkOJyErgv8DJwBtADVW9KJdrSonILBFZICJLROTJoPxkERkvIiuCx5NCrukjIskislxELg8pbyQii4LXXhYJydvsXCR9953tXdqzJ7RqBQsW7A8Ue/ZY/LjkEoshM2d6oHBFR16nzlZX1StV9RlVnZLHMYs9QEtVbQDEAa1FpAnQG0hU1epAYvAcEakNtAfqAK2BQcEufWB5qToD1YOf1jgXSStWQLt2lp5jxw74/HMYPRr+9jcA5s61Qet+/SxFR1KSrcVzrqjIa7A4S0QSRWQxgIjUF5FHc7pAzY7gafHgR4G2wL6U50OBa4PjtsAIVd2jqquBZKCxiFQAyqjqdFVVLInhvmucC68NG6BrV6hd22Y8Pf44LF26P5V4Whr07QuNG9tCuzFjbHOi44+PdsWdy195DRZvAX2ANABVXYi1AnIkIsVEZD6wERivqjOBU1U1NXifVP7MMVUR+Dnk8pSgrGJwfHB5Vp/XWUSSRCRp06ZNebw157Kwd68thKhe3dJ03H03rFwJTz4JxxwDwLJl0LSpFe0b527TJsr1di5M8hosjlHVWQeVped2kapmqGocNijeWETq5nB6VuMQmkN5Vp+XoKrxqhpfvnz53KrnXNa+/RYaNLBxiQsvtJbEq6/CqacCliH2pZfgnHPgp58sZcfw4XCyL1F1RVheg8WvIlKN4EtaRK4HUvP6Iar6OzAJG2vYEHQtETxuDE5LwWZb7VMJWB+UV8qi3Ln8tW2b7TVxySW218TYsfZTvfr+U9avt/Hs7t3ttMWLbf8J54q6vAaLbsCbQE0RWYdlob0npwtEpLyInBgclwZaAT8Ao/kzY20HYFRwPBpoLyIlRaQqNpA9K+iq2i4iTYJZULeFXONc/hg3zhbTDRliS6wXLoSrrtr/sip88IENWn//Pbzxho1PBOPbzhV5eV1nsQpoJSLHYgHmD6AdsCaHyyoAQ4MZTUcBI1V1rIhMB0aKSCdgLXBD8BlLRGQksBTr4uqmqhnBe3UB3gVKA+OCH+f+utRUayaMHGmD2NOmwXnnHXDKihU2xj1hApx7Lrz3nu1h5FwsEZtglM2LImWwVkVF7H/zE4LnPYEFqto2EpU8EvHx8ZqUlBTtariCKjMTEhLgX//6c4HEQw/tX4ENsGsXPPec/ZQsaQu077kHihXL4X2dK+REZI6qHpK9LLeWxXvAFmA6cBfQCygBXKuq8/O7ks5FxOrV0KmT7X/dqpWlgg0Zl1CFzz6zDB5r1thMpxde8E2JXGzLLVicqar1AERkMPArcLqqbg97zZzLb6q2Z2nPnpYR9q23LGiEJARYvRq6dLE9i+rWtXgSbJPtXEzLbYA7bd9BMH6w2gOFK5RSU+HKKy0SNG1q05juvHN/oEhPhwEDbFOiqVNh4ECYN88DhXP75NayaCAi24JjAUoHzwVbpF0mrLVz7q9ShU8/tUV1f/xh6yW6dj2gNZGcDP/4h22TffXVlm28cuUc3tO5GJRjsFBVH8pzhdeqVbYJ0RdfZDuN6f33bdD66KPho4/ghhsOiCPOuUBe11k4V3js3Qv//rf1KX33naXtmDr1gECxfTt06AC33GJbmy5YADfe6IHCuezkdfMj5wqHuXMtL/iiRfbt/8ILtk1diNmzbb+J1astL+Bjj1nLwjmXPW9ZuKJhxw5bK9G4Mfz6q6UP/+ijAwLFH3/A009Ds2bW+Jg0yZIAeqBwLnf+z8QVbrt2weuv28q5TZvgtttsKtNJ+/fUIi0N3n7b9sJev97GJd5884BTnHO58JaFK7w+/RSqVbN1E3Fxlqpj6NADosDkybZe4p574IwzbN3EyJEeKJw7XB4sXOHz66+2rPr6662bafJk+OYbWz8R2L4dunWDiy6yNRSjR9sYt6+bcO7IeDeUK1w+/9zWTGzZYgMQvXpB8eIHnDJ7tnU1rV1rOQKffhqOPTYqtXWuyPBg4QqHLVtszcTw4bYx0Tff2ONBhgyxNXcVKlgq8WbNolBX54og74ZyBd++RE0jRsATT8CsWYcEiu3bbd+iO++0ze2SkjxQOJefPFi4gmvXLrj3Xtua7sQTYeZM6NsXSpTYf4qqrcKuUcPyAvbuDV99BeXKRa3WzhVJ3g3lCqY5cyxh048/Wq7wfv2gVKkDTpk/32LJ1KmWzeOzzw7Zt8g5l0+8ZeEKFlV46SWb2bRrFyQmWrqOkECxZYsFiUaNLJYMGQIzZnigcC6cvGXhCo7Nm+GOO2ye69VXwzvvQNmy+19OT7eupieesFO7dbOFdieeGL0qOxcrvGXhok/VMsLWrAnjxsGLL8KoUfsDharFj3r1bKZTrVrWS/Xyyx4onIsUDxYuulauhEsvtTQd1arZNKbu3fenf50xwxbWtW1rQWPUKMvpFBcXzUo7F3vCFixEpLKITBSRZSKyRETuD8pPFpHxIrIieDwp5Jo+IpIsIstF5PKQ8kYisih47WURTyRd6KlCQgLUr2+r6AYNsnQd9esDNhZx3XU2dPHjj7Yh0aJFcM01nkbcuWgIZ8siHeihqrWAJkA3EakN9AYSVbU6kBg8J3itPVAHaA0MEpF9my+9DnQGqgc/rcNYbxduv/xi3/p3323RYMkS2+70qKP49Vdbe1enjq27e/JJ28mua9dDFmo75yIobMFCVVNVdW5wvB1YBlQE2gJDg9OGAtcGx22BEaq6R1VXA8lAYxGpAJRR1emqqsCwkGtcYZKRYRlia9WCCRNs1tM330ClSqSn29OzzrJWRKdOFiQefxyOOy7aFXfORWQ2lIhUARoCM4FTVTUVLKCIyCnBaRWBGSGXpQRlacHxweWuMJk3z1oSs2fDxRdbt1PNmoAtyL7nHjvl8sttpmydOlGur3PuAGEf4BaR44BPge6qui2nU7Mo0xzKs/qsziKSJCJJmzZtOvzKuvyXlmZ9SY0bW2a/99+3tRM1a7Jpk8WPJk1gwwb4+GObDOWBwrmCJ6zBQkSKY4HifVX9X1C8IehaInjcGJSnAJVDLq8ErA/KK2VRfghVTVDVeFWNL1++fP7diDsyS5dagqa+faFdO1i2DP7xD9LShYEDoXp1W1B3//320vXX++C1cwVVOGdDCTAEWKaqL4S8NBroEBx3AEaFlLcXkZIiUhUbyJ4VdFltF5EmwXveFnKNK4i2brUNiRo0sI2uP/4Yhg9HTzyJTz+1nIAPPGArrhcutGUVZcpEu9LOuZyEc8yiOXArsEhE5gdlDwPPAiNFpBOwFrgBQFWXiMhIYCk2k6qbqmYE13UB3gVKA+OCH1fQpKfbTnUPP2xbnN5xBzzzDJxyClOnQo8elguwdm0YMwauuspbEs4VFmELFqr6PVmPNwBcks01/YB+WZQnAXXzr3YuX2VmwkcfWR6OFStsOuwXX0B8PFu2QK+7YPBg29RuyBBbf3e0J5pxrlDxf7Lur1m4EDp0sBSwdeta6te2bVGEkR/ZmonNm+GhhyyW+I51zhVOnu7DHZnMTBgwwHKD//ILfPABLFgA117Lr5uFdu1sm+wzzrAMHs8/74HCucLMWxbu8K1ZAx07WpKmv//d0naUK4cq/O9TW229ZQv072/j3N7l5Fzh5y0Ll3eqlja8Xj1L+/r22/Dpp1CuHN99B82b2/TX006zl3v39kDhXFHhwcLlzbp1lvr1jjvgnHNsrOL221n+o3DlldCihTU43nzTVmTXqxftCjvn8pMHC5ezzExLzVGrFowfb7k4vv2W7WWr0KuXBYWpU21MIjkZOnf2hH/OFUXeSeCyt3KlzXOdNg0uuQTeeAOtdhbvvw+9ekFqKtx+u41NnHpqtCvrnAsnb1m4rH30ETRsaCk7hg6F8eOZv+MsLrwQbr0VKlWyjYneftsDhXOxwIOFO9D27daX1L69rZuYP5+0m27jsceFRo3ghx9sgd2MGZauwzkXGzxYOKNqrYlateCtt2wq03ffsXTnGTRpAk8/bT1SP/5oe00c5X9znIsp/k/eWcrXSy+11sQpp8D06WT268/A14rTqJFlFv/f/2zW7Ekn5f52zrmix4NFLNu+3fJw1K9vCyNeew1mz+bnik249FLLDNuqFSxebGvvnHOxy2dDxaovv4S77oL1661fqX9/Mk4uv78HKiPDeqM6dfLMsM45b1nEnrQ0iwZXXQXlytlI9eDBzFpdnvPOgy5dbM3dggVw550eKJxzxoNFLFm71va/fu452/R65kwWH3se7drZ1qbr18OHH9qup2eeGe3KOucKEu+GigWqNt+1Rw87/uADVje5iV63wiefwPHHQ58+1uA4/vhoV9Y5VxB5sCjqfv7Z+pO++cZaFUOGMHJ2Ve6Ks7jx2GPQvTucfHK0K+qcK8g8WBRlI0ZYd1N6OgwaxK5b7+aBHkeRkGDdTh9+CFWqRLuSzrnCwMcsiqKtWy0nx0032SK7BQtIPLsL9eMsUPzrXzB5sgcK51zeebAoSlRh+HCoWdOaDX37svnzKdz+dDVatbKZTd9+C88+65lhnXOHJ2zBQkTeFpGNIrI4pOxkERkvIiuCx5NCXusjIskislxELg8pbyQii4LXXhbxyZxZWrgQLrjAWhSVK5M5dTqDKz5BjTpHM3y4DWAvXGjDFs45d7jC2bJ4F2h9UFlvIFFVqwOJwXNEpDbQHqgTXDNIRIoF17wOdAaqBz8Hv6d7+21o3NgSNw0ZwsKEGTTvfi533QW1a8PcufDMM1C6dLQr6pwrrMIWLFR1MvDbQcVtgaHB8VDg2pDyEaq6R1VXA8lAYxGpAJRR1emqqsCwkGvc7t22CrtTJ7jgAnTxEt7YeweNmxzFqlUwbBh8953vWuec++siPRvqVFVNBVDVVBE5JSivCMwIOS8lKEsLjg8ud4sXW5fT/Pnw8MNs6/kUnbsU46OPoHVreO89W6DtnHP5oaAMcGc1DqE5lGf9JiKdRSRJRJI2bdqUb5UrUDIyYMAAaNQI1q1DR4/h47h+1KlfjE8+scHrL77wQOGcy1+RDhYbgq4lgseNQXkKUDnkvErA+qC8UhblWVLVBFWNV9X48uXL52vFC4QVK6BFC8sUe9VVLP10Ga0GtuHGG6FsWZgyxabF+l4Tzrn8FumvldFAh+C4AzAqpLy9iJQUkarYQPasoMtqu4g0CWZB3RZyTezIyIAXX4QGDWDRIna+OZze1T+lQcuyzJ1rmcXnzIGmTaNdUedcURW2MQsR+RBoAZQTkRTgCeBZYKSIdALWAjcAqOoSERkJLAXSgW6qmhG8VRdsZlVpYFzwEzt+/BFuvx2mTUOvasPnfx9K96dOZu1a6NgRnn8eimIjyjlXsIhNMip64uPjNSkpKdrVOHIZGfDSS/DII1C6NBPvHsHDky5lxgyhTh14/XVbVuGcc/lJROaoavzB5Z4bqiBatco2vJ46lZUt7+JefZmvni1FpUq2IVHHjnC0/8k55yLIv3IKElWb83rvveyVkgy4YS7/HhNHiRLCgAHQrRuUKhXtSjrnYpHPmykotmyxxH8dOjCx6h2c87d1PPJxQ9q0EZYts60oPFA456LFWxYFQWIidOxISmoxetZbwkcLa1OlCoweDVdfHe3KOeectyyia8cOePBB9ra6gud330eN4isZtaI2Tz4JS5d6oHDOFRzesoiGjAx491149FEm/VKDrietYdmvFWjbFgYO9H0mnHMFjweLSFuwADp0YM2CLTxUdjgfcwlVToAxw6BNm2hXzjnnsubdUJGiCgkJbG98CY+v7EDN4qsYu6slffvCkiUeKJxzBZu3LCJh61Z2de7OoJFlebb4SjbvOIGbboLnnoPKlXO/3Dnnos2DRTipsvPD0STcM5fntz/DL1SgdUvlqX/DuedGu3LOOZd3HizCZMfydbx07UQG/nA5v9KWi+O3MfIFuOAC3xXWOVf4+JhFfktPZ1Sn0dSulcmjP9xC45rbmPpdOt/OLuO5nJxzhZa3LPJRytj53HvLFkZtvYa6x/3Eh2+vp/kN1aJdLeec+8u8ZZEPdMvvvHXx+9S5uirfbGvCc7csZO7mM2h+w2nRrppzzuULDxZ/RUYGPz77Py7920I6T7qZRpU2sHheOr3eq0/xEj424ZwrOrwb6kiosnzI9zz90O988HtbjjlqN6/3WUvnp8/2LU2dc0WSB4vDtG3Vr/RqmcRbay6llOzhwatX0DOhBqf+7dhoV80558LG/x98GL7pN5u61Xfz1ppLue/8eaxeezT/GV2TU//mXU7OuaLNWxZ5sGPTH/RoOZeExc2pWXIV0wav4rxbDtl10DnniiwPFrmYNfxHbu5UkpV7m/LQOYk8NaEZpU4qHe1qOedcRHk3VDZ2/raHxy7+nma3nsnejGJM/M8cnp9ziQcK51xMKjTBQkRai8hyEUkWkd7h+pyMdOXt+xdQ/ZTfeXrS+fzj9KksWF6ai3p6MifnXOwqFN1QIlIMeA24FEgBZovIaFVdmp+fk747nWZ/W8XsrQ1oUmo+nw74iabdL8rPj3DOuUKpUAQLoDGQrKqrAERkBNAWyNdgcXSpo7m+3nJ6VF3BjYMvQ0oUz8+3d865QquwBIuKwM8hz1OA8w4+SUQ6A50BTj/99CP6oF5TfONr55w7WGEZs8hqIYMeUqCaoKrxqhpfvnz5CFTLOediQ2EJFilA6J5ylYD1UaqLc87FnMISLGYD1UWkqoiUANoDo6NcJ+ecixmFYsxCVdNF5F7ga6AY8LaqLolytZxzLmYUimABoKpfAl9Gux7OOReLCks3lHPOuSjyYOGccy5XHiycc87lSlQPWa5QJIjIJmDNEV5eDvg1H6tTGMTiPUNs3ncs3jPE5n0fyT2foaqHLFQrssHirxCRJFWNqQ0rYvGeITbvOxbvGWLzvvPznr0byjnnXK48WDjnnMuVB4usJUS7AlEQi/cMsXnfsXjPEJv3nW/37GMWzjnncuUtC+ecc7nyYBEiUlu3RpuIVBaRiSKyTESWiMj9QfnJIjJeRFYEjydFu675TUSKicg8ERkbPI+Fez5RRD4RkR+CP/OmRf2+ReSB4O/2YhH5UERKFcV7FpG3RWSjiCwOKcv2PkWkT/D9tlxELj+cz/JgEQjZuvUKoDZwk4jUjm6twiYd6KGqtYAmQLfgXnsDiapaHUgMnhc19wPLQp7Hwj2/BHylqjWBBtj9F9n7FpGKwH1AvKrWxZKPtqdo3vO7QOuDyrK8z+DfeHugTnDNoOB7L088WPxp/9atqroX2Ld1a5GjqqmqOjc43o59eVTE7ndocNpQ4NqoVDBMRKQScBUwOKS4qN9zGeBCYAiAqu5V1d8p4veNJUktLSJHA8dg+98UuXtW1cnAbwcVZ3efbYERqrpHVVcDydj3Xp54sPhTVlu3VoxSXSJGRKoADYGZwKmqmgoWUIBToli1cBgI9AIyQ8qK+j2fCWwC3gm63waLyLEU4ftW1XXAAGAtkApsVdVvKML3fJDs7vMvfcd5sPhTnrZuLUpE5DjgU6C7qm6Ldn3CSUTaABtVdU606xJhRwPnAK+rakNgJ0Wj+yVbQR99W6AqcBpwrIjcEt1aFQh/6TvOg8WfYmrrVhEpjgWK91X1f0HxBhGpELxeAdgYrfqFQXPgGhH5CetibCkiwyna9wz29zpFVWcGzz/BgkdRvu9WwGpV3aSqacD/gGYU7XsOld19/qXvOA8Wf4qZrVtFRLA+7GWq+kLIS6OBDsFxB2BUpOsWLqraR1UrqWoV7M/2W1W9hSJ8zwCq+gvws4jUCIouAZZStO97LdBERI4J/q5fgo3LFeV7DpXdfY4G2otISRGpClQHZuX1TX1RXggRuRLr1963dWu/6NYoPETkfGAKsIg/++8fxsYtRgKnY//gblDVgwfPCj0RaQH0VNU2IlKWIn7PIhKHDeqXAFYBt2P/USyy9y0iTwLtsJl/84A7geMoYvcsIh8CLbDsshuAJ4DPyeY+ReQR4A7s99JdVcfl+bM8WDjnnMuNd0M555zLlQcL55xzufJg4ZxzLlceLJxzzuXKg4VzzrlcebBwLkKC7K9do10P546EBwvnIudEwIOFK5Q8WDgXOc8C1URkvoj8J9qVce5w+KI85yIkyPA7NthjwblCxVsWzjnncuXBwjnnXK48WDgXOduB46NdCeeOhAcL5yJEVTcDU0VksQ9wu8LGB7idc87lylsWzjnncuXBwjnnXK48WDjnnMuVBwvnnHO58mDhnHMuVx4snHPO5cqDhXPOuVx5sHDOOZer/wdXp7dEHnSVkQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Rewards\")\n",
    "plt.plot(np.cumsum(np.mean(sw_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"SW UCB\",\"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Questa volta SW-UCB si comporta meglio!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SD1-UCB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#Comparison between SD1-UCB and UCB\n",
    "# static environment\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 20\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "cd_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "cd_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    cd_UCB_learner = CD1_UCB(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = cd_UCB_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm, )\n",
    "        cd_UCB_learner.update(pulled_arm, reward)\n",
    "\n",
    "    cd_ucb_rewards_per_experiment.append(cd_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    cd_ucb_pulls_per_arm_per_experiment.append(cd_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt - cd_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(opt - ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"CD1-UCB\",\"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [ 51.59780352 103.19560704 154.79341056 206.39121408 257.9890176 ]\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [ 61.91736422 123.83472845 185.75209267 247.6694569  309.58682112]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison between SD1-UCB and UCB\n",
    "# dynamic environment\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 100\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "window_size = 50\n",
    "\n",
    "days_of_change = [50, 70]\n",
    "\n",
    "\n",
    "cd_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "cd_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    cd_UCB_learner = CD1_UCB(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "        for day_of_change in days_of_change:\n",
    "            if d==day_of_change:\n",
    "                env.abrupt_change([0],1.20)\n",
    "\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = cd_UCB_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm, )\n",
    "        cd_UCB_learner.update(pulled_arm, reward)\n",
    "\n",
    "    cd_ucb_rewards_per_experiment.append(cd_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    cd_ucb_pulls_per_arm_per_experiment.append(cd_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Rewards:\")\n",
    "plt.plot(np.cumsum(np.mean(cd_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"CD1-UCB\",\"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CU-SUM UCB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day  0\n",
      "[0 0 0 0 0]\n",
      "day  1\n",
      "[1 1 1 1 1]\n",
      "day  2\n",
      "[2 2 2 2 2]\n",
      "day  3\n",
      "[3 3 3 3 3]\n",
      "day  4\n",
      "[0 0 0 0 0]\n",
      "day  5\n",
      "[1 1 1 1 1]\n",
      "day  6\n",
      "[2 2 2 2 2]\n",
      "day  7\n",
      "[3 3 3 3 3]\n",
      "day  8\n",
      "[3. 3. 2. 2. 2.]\n",
      "day  9\n",
      "[3. 3. 2. 2. 2.]\n",
      "day  10\n",
      "[3. 3. 2. 2. 3.]\n",
      "day  11\n",
      "[3. 3. 3. 2. 1.]\n",
      "day  12\n",
      "[3. 3. 3. 2. 1.]\n",
      "day  13\n",
      "[3. 3. 3. 2. 1.]\n",
      "day  14\n",
      "[3. 3. 2. 2. 1.]\n",
      "day  15\n",
      "[3. 3. 2. 2. 1.]\n",
      "day  16\n",
      "[3. 3. 2. 2. 2.]\n",
      "day  17\n",
      "[3. 3. 2. 2. 1.]\n",
      "day  18\n",
      "[3. 3. 2. 2. 2.]\n",
      "day  19\n",
      "[3. 3. 2. 2. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison between CU-SUM UCB and UCB\n",
    "# static environment\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 20\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "window_size = 10\n",
    "\n",
    "cd_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "cd_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha, fixed_weights, fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    cd_UCB_learner = CUSUM_UCB(n_arms)\n",
    "\n",
    "    for d in range(n_days):\n",
    "        print('day ', d)\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = cd_UCB_learner.pull_arm()\n",
    "        print(pulled_arm)\n",
    "        reward = env.round(pulled_arm, )\n",
    "        cd_UCB_learner.update(pulled_arm, reward)\n",
    "\n",
    "    cd_ucb_rewards_per_experiment.append(cd_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "    cd_ucb_pulls_per_arm_per_experiment.append(cd_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.plot(np.cumsum(np.mean(opt - cd_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(opt - ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"CUSUM-UCB\", \"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------day-------- 0\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 1\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 2\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 3\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 4\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 5\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 6\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 7\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.42857142857142855\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 8\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 9\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 10\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 11\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 12\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 13\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5714285714285714\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease -0.05759749178333644\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 14\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.07738666361542024\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease -0.07637297878457397\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.28768207245178085\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 15\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease -0.11519498356667288\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 16\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.06880903105992392\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.0656691035078573\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.3184537311185345\n",
      "--------day-------- 17\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.1313382070157146\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 18\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.15477332723084047\n",
      "estimated probability  0.5714285714285714\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease -0.00756394772465005\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease 0.227057450635346\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 19\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.07484789079643238\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.17045198123857086\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.1970073105235719\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 20\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.2321599908462607\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.2692167153436592\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.0779615414697118\n",
      "--------day-------- 21\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.14969578159286476\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease -0.08393692650922402\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 22\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.30954665446168095\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.06124508333527387\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.2626764140314292\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.06453852113757118\n",
      "--------day-------- 23\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.8888888888888888\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease 0.09959604447122626\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.6536284142539912\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease 0.16643282881891114\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.25903031064773374\n",
      "--------day-------- 24\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease 0.028740107703881662\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.06963369175880076\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease 0.10580820700247628\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.06180040090544682\n",
      "--------day-------- 25\n",
      "estimated probability  0.625\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.3869333180771012\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.10109611687136881\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease 0.04518358518604143\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.19960689017693298\n",
      "--------day-------- 26\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.22454367238929712\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.5960309224706548\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.015441036630393423\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.1401834697061322\n",
      "--------day-------- 27\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.2993915631857295\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.04211582906346294\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.05989814158106896\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.32834551753928654\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.059423420470800764\n",
      "--------day-------- 28\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.4643199816925214\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.20642709317977176\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.5384334306873184\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.07606565844682828\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.11884684094160153\n",
      "--------day-------- 29\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.08159864388287942\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.0779615414697118\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease 0.0020052142271379247\n",
      "estimated probability  0.2857142857142857\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.12907704227514236\n",
      "--------day-------- 30\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.16319728776575884\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.1559230829394236\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.1392673835176015\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.05684886423215264\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.4586372008246667\n",
      "--------day-------- 31\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.5417066453079417\n",
      "estimated probability  0.2\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.3516091030242696\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.11979628316213792\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.13669028026326313\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.1782702614124023\n",
      "--------day-------- 32\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.4000561282449148\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.11297176583080754\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.09708568841709296\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.39401462104714385\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.016161140564264986\n",
      "--------day-------- 33\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.1483513057728636\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.18382770259815212\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.19617659106132385\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.11369772846430529\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.12360080181089364\n",
      "--------day-------- 34\n",
      "estimated probability  0.42857142857142855\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.258405611181888\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.2546836393654967\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.48083593890398196\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.19731490207969798\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.19361556341271352\n",
      "--------day-------- 35\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.5714285714285714\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.3255395761328413\n",
      "estimated probability  0.42857142857142855\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.865247637814314\n",
      "estimated probability  0.7777777777777778\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.45968372455500117\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.2581540845502847\n",
      "--------day-------- 36\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.24479593164863828\n",
      "estimated probability  0.625\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.3963955129001859\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.20890107527640228\n",
      "estimated probability  0.7\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.5253528280628584\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.23769368188320306\n",
      "--------day-------- 37\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.223199196569296\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.46725144966753046\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.278534767035203\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.25793952389613284\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.3226926056878559\n",
      "--------day-------- 38\n",
      "estimated probability  0.625\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.3357922747973082\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.5381073864348751\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.17969442474320688\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.5910219315707157\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.2971171023540038\n",
      "--------day-------- 39\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.3263945755315177\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.6089633232022197\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.09508047418995504\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.656691035078573\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.7770909319432011\n",
      "--------day-------- 40\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.2980470873657284\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.6798192599695643\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.8076501460309776\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.7223601385864302\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease 0.045639260341181834\n",
      "--------day-------- 41\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.19414175773428138\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.7506751967369089\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 1.1920618449413096\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.7880292420942875\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.35654052282480453\n",
      "--------day-------- 42\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.3728949781621608\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.23388462440913543\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.34816845879400377\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.3185641457125677\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.03232228112852997\n",
      "--------day-------- 43\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.4079932194143971\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.580223215498338\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.19417137683418592\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.8536983456021447\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.3872311268254271\n",
      "--------day-------- 44\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.052491240671254547\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.3118461658788472\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.23959256632427584\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.919367449110002\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.41596394329560527\n",
      "--------day-------- 45\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.44774286895859317\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.389807707348559\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.2932622794784168\n",
      "estimated probability  0.7777777777777778\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.9850365526178593\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.11028382259824178\n",
      "--------day-------- 46\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666668\n",
      "cumul_decrease -0.059423420470800764\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.4677692488182708\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.3923531821226477\n",
      "estimated probability  0.375\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.7744717835105096\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.4517696479629983\n",
      "--------day-------- 47\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.5225907597550256\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.5457307902879827\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.1344643531579732\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.5163081691005694\n",
      "--------day-------- 48\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.4895918632972765\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.4178021505528045\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.029478119776916847\n",
      "--------day-------- 49\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.12987790428667478\n",
      "estimated probability  0.5714285714285714\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.6510791522656826\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.49144408476687856\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.17054659269645794\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.5808466902381406\n",
      "--------day-------- 50\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [ 3418.21891872  6836.43783743 10254.65675615 13672.87567487\n",
      " 17091.09459358]\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.20726456790209502\n",
      "estimated probability  0.5714285714285714\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.2752361242396957\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.0768668613746368\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.22739545692861057\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.6453852113757118\n",
      "--------day-------- 51\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.597438650551458\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.1988631454551217\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.39034796789550974\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.37918876752900255\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.7176675114724004\n",
      "--------day-------- 52\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.06561405083906818\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.12249016667054774\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.0192693695913004\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.0915066950772217\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.709923732513283\n",
      "--------day-------- 53\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.571190507180156\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.2676721765150456\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.2994907079053448\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.2842443211607632\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.7744622536508542\n",
      "--------day-------- 54\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.6722865413478903\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.4128541863595435\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.961671877807964\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.8401408870183669\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.475387363766406\n",
      "--------day-------- 55\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.14300071445448842\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.3364812075749696\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.3593888494864138\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.34109318539291583\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.6582440910015996\n",
      "--------day-------- 56\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.0013501973914615828\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.26010822879039563\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.9040743860246276\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.9058099905262241\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.9766978221201341\n",
      "--------day-------- 57\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.6527891510630354\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.18373525000582167\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.48743584231160525\n",
      "estimated probability  0.25\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.08128263343685696\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.8390007747884254\n",
      "--------day-------- 58\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.7471344321443227\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.32891725985031955\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.4894388705397406\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.15213131689365655\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.5348107842372067\n",
      "--------day-------- 59\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666668\n",
      "cumul_decrease -0.11884684094160153\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8866666666666667\n",
      "cumul_decrease -0.058043369649915154\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.5885297731839715\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.2127559387100914\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.04848342169279496\n",
      "--------day-------- 60\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.8219823229407551\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.7219350890330272\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.8464768942412912\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.27338056052652626\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.12644496316250675\n",
      "--------day-------- 61\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.14030031967156525\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.40596884791282384\n",
      "estimated probability  0.2\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.48743365631260266\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -0.9714790940340814\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.9035392959259966\n",
      "--------day-------- 62\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.8968302137371875\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.25254428106574556\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.7888794024579548\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.0371481975419388\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.20440650463221854\n",
      "--------day-------- 63\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease 0.06291365605614502\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.7927910258003718\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.557069534070406\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.1028173010497961\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.5942342047080075\n",
      "--------day-------- 64\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.7343877949459148\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.6223390445618009\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.4192869910674828\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.1684864045576535\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -0.9680778170635678\n",
      "--------day-------- 65\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -0.9716781045336199\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.3977262909102435\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 0.7312819106746185\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.39794204962506846\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.6536576251788082\n",
      "--------day-------- 66\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.01447300755927522\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.6931949813291455\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 1.1156936095849506\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.3340051823429611\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.28236804610193034\n",
      "--------day-------- 67\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.09185967117469546\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.32135331212566953\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.6267032258292068\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.39462980415939597\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.36032958757164213\n",
      "--------day-------- 68\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.1692463347901157\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.24498033334109556\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 1.5001053084952827\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.4552544259758308\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.2205676451964835\n",
      "--------day-------- 69\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.24663299840553593\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.1686073545565216\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.4791851326485518\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.5158790477922657\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.713081045649609\n",
      "--------day-------- 70\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [ 4101.86270246  8203.72540492 12305.58810738 16407.45080984\n",
      " 20509.3135123 ]\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.8159864388287942\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.31378936440101945\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.5865245589568335\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.22819697534048483\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.9172744016493334\n",
      "--------day-------- 71\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.32401966202095617\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.23741638561644549\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.6963369175880075\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.2341555080655109\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.7725044661204097\n",
      "--------day-------- 72\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.0465259953300523\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.16104340683187152\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.4854284420854647\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.2998246115733683\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.8578509811785326\n",
      "--------day-------- 73\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.1213738861264846\n",
      "estimated probability  0.25\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.3062254166763694\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 1.8845170074056148\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.3654937150812256\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.0326163382011389\n",
      "--------day-------- 74\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666668\n",
      "cumul_decrease -0.1782702614124023\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.7640509180964901\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.7659706093468083\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.431162818589083\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.09715485933871\n",
      "--------day-------- 75\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.18236914495792933\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.8349068548638346\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.5390832742296208\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.4968319220969404\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.161693380476281\n",
      "--------day-------- 76\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.8975850827116736\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.9057627916311792\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.8269195156222784\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.2888215971569197\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.226231901613852\n",
      "--------day-------- 77\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.25975580857334957\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.4514074265208673\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.769322023838942\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.34944621897335454\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.2985291866661953\n",
      "--------day-------- 78\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.1962217769229169\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.48393038938253563\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.7117245320556056\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.4100708407897894\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.3764907281359071\n",
      "--------day-------- 79\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -0.979183726594553\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.5618919308522474\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.5845193447296956\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.47069546260622425\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.2907704227514232\n",
      "--------day-------- 80\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.2710696677193491\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.9766187283985238\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.23370162467843886\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.5625010256047978\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.7984275607077319\n",
      "--------day-------- 81\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.3371424721887698\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -1.0474746651658684\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.48342322785832675\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.4547909138572211\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.4544522696056189\n",
      "--------day-------- 82\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -1.0607823704774324\n",
      "estimated probability  0.42857142857142855\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.8770226839272975\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.6541270402722692\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.5116397780893738\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.8319278865912104\n",
      "--------day-------- 83\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.41452913580419004\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.6398534723219592\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.835604301105609\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.5313200844226591\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.8913513070620112\n",
      "--------day-------- 84\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.2728786187411632\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.717815013791671\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 2.0385387391826013\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.5919447062390939\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.7390041402369312\n",
      "--------day-------- 85\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.3459175585157814\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.7957765552613828\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.5825141305025576\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.6525693280555287\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.3553089438889943\n",
      "--------day-------- 86\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.13122810167813637\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.8737380967310946\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.980941247399265\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.6281701291126551\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666666\n",
      "cumul_decrease -0.5324138110753307\n",
      "--------day-------- 87\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666668\n",
      "cumul_decrease -0.23769368188320306\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -0.9516996382008064\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 1.9233437556159285\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9047619047619048\n",
      "cumul_decrease -0.5684886423215264\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.3926518687001721\n",
      "--------day-------- 88\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6380952380952382\n",
      "cumul_decrease -1.142381014360312\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -1.0296611796705182\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.6816050331467886\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.6938392326205125\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.6795807197661304\n",
      "--------day-------- 89\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.4207654493122137\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.5965894363653652\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 2.3077554545262604\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.7595083361283699\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.6201572992953297\n",
      "--------day-------- 90\n",
      "estimated probability  0.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.2086147652935566\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6799999999999999\n",
      "cumul_decrease 0.5202164575807913\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.9052379928644098\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.7131939498719635\n",
      "estimated probability  0.3333333333333333\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.9386110304138642\n",
      "--------day-------- 91\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.28600142890897684\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 0.6653984674252892\n",
      "estimated probability  0.5714285714285714\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.53\n",
      "cumul_decrease -0.7806959357910195\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "cumul_decrease -0.7738185716883983\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.4198474650265653\n",
      "--------day-------- 92\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.495613340108646\n",
      "estimated probability  0.7142857142857143\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -0.9478786206946421\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.2935997662595078\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.8251774396362273\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.4843859861641364\n",
      "--------day-------- 93\n",
      "estimated probability  0.4\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -1.34457308269578\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -1.10762272114023\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -0.9748716846232105\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.8908465431440846\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "cumul_decrease -1.5489245073017075\n",
      "--------day-------- 94\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -1.0129699407088095\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8866666666666667\n",
      "cumul_decrease -0.11608673929983031\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease 2.6921671534365923\n",
      "estimated probability  0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -1.956515646651942\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -0.9507747275328119\n",
      "--------day-------- 95\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.14435091184595\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -1.185584262609942\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.86\n",
      "cumul_decrease -0.3534979078405768\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -2.0221847501597994\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease -1.0101981480036126\n",
      "--------day-------- 96\n",
      "estimated probability  0.8571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.22173757546137024\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -1.0187345574619868\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.6795998189196507\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -2.0878538536676565\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.8791876099430634\n",
      "--------day-------- 97\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6714285714285714\n",
      "cumul_decrease -0.2991242390767905\n",
      "estimated probability  0.8333333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8866666666666667\n",
      "cumul_decrease -0.17413010894974545\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -1.0445053763820114\n",
      "estimated probability  0.7777777777777778\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -2.1535229571755137\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.8197641894722627\n",
      "--------day-------- 98\n",
      "estimated probability  0.25\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.15747372201376364\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6666666666666667\n",
      "cumul_decrease -1.263545804079654\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7433333333333334\n",
      "cumul_decrease -1.114139068140812\n",
      "estimated probability  0.5\n",
      "running CUSUM algorithm\n",
      "cumul_decrease -0.48613649923661745\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.760340769001462\n",
      "--------day-------- 99\n",
      "estimated probability  0.6666666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6933333333333334\n",
      "cumul_decrease -1.4194209734922123\n",
      "estimated probability  0.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.730952380952381\n",
      "cumul_decrease -1.0895904942293315\n",
      "estimated probability  0.8\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8933333333333333\n",
      "cumul_decrease 2.6345696616532557\n",
      "estimated probability  0.625\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7866666666666667\n",
      "cumul_decrease -2.219192060683371\n",
      "estimated probability  1.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8666666666666666\n",
      "cumul_decrease 0.7009173485306612\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison between CUSUM-UCB and UCB\n",
    "# dynamic environment\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 100\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "window_size = 50\n",
    "\n",
    "days_of_change = [50, 70]\n",
    "\n",
    "\n",
    "cd_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "cd_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    cd_UCB_learner = CUSUM_UCB(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "        print('--------day--------', d)\n",
    "        for day_of_change in days_of_change:\n",
    "            if d==day_of_change:\n",
    "                env.abrupt_change([0],1.20)\n",
    "\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = cd_UCB_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        cd_UCB_learner.update(pulled_arm, reward, env.purchases_current_day,env.clicks_current_day)\n",
    "\n",
    "    cd_ucb_rewards_per_experiment.append(cd_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    cd_ucb_pulls_per_arm_per_experiment.append(cd_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Rewards:\")\n",
    "plt.plot(np.cumsum(np.mean(cd_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"CUSUM-UCB\",\"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------day-------- 0\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 1\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 2\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 3\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 4\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 5\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 6\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 7\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 8\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 9\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 10\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 11\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 12\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 13\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 1.8385714285714283\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 14\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 15\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 16\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 0.7766666666666667\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0.09999999999999981\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 0\n",
      "g_decrease 1.2\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 17\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 0.875\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 4.128571428571428\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 18\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0.15714285714285714\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "g_increase 0\n",
      "g_decrease 0.7999999999999999\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 19\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 2.4366666666666674\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 1.125\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.05\n",
      "g_decrease 0\n",
      "--------day-------- 20\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0.42666666666666647\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0\n",
      "g_decrease 1.7085714285714286\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.1\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 21\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 2.057142857142857\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 0\n",
      "g_decrease 1.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.6766666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.1500000000000004\n",
      "g_decrease 0\n",
      "--------day-------- 22\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 0.7933333333333333\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "g_increase 0\n",
      "g_decrease 0.7999999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 0.6599999999999999\n",
      "g_decrease 0.6628571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.2000000000000006\n",
      "g_decrease 1.0999999999999999\n",
      "--------day-------- 23\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 3.8733333333333353\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0.14999999999999972\n",
      "g_decrease 0.37500000000000006\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.2500000000000009\n",
      "g_decrease 0.7499999999999998\n",
      "--------day-------- 24\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 2.114285714285714\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 1.7500000000000002\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 0.8833333333333332\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0.5633333333333334\n",
      "g_decrease 0.6766666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.3000000000000012\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 25\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.5866666666666667\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0.47499999999999987\n",
      "g_decrease 0.605\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 0\n",
      "g_decrease 1.0199999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.03\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "--------day-------- 26\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 4.7566666666666695\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0\n",
      "g_decrease 1.21\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "g_increase 0\n",
      "g_decrease 0.7999999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 0.3199999999999996\n",
      "g_decrease 1.3257142857142856\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0.6500000000000001\n",
      "g_decrease 0\n",
      "--------day-------- 27\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0.7\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 1.7500000000000002\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 0.8999999999999999\n",
      "g_decrease 0.4000000000000003\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 4.257142857142857\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.3000000000000005\n",
      "g_decrease 0\n",
      "--------day-------- 28\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 2.5999999999999996\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0.14999999999999972\n",
      "g_decrease 1.0000000000000002\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 1.4\n",
      "g_decrease 0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0.1485714285714288\n",
      "g_decrease 3.708571428571429\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0.9500000000000007\n",
      "g_decrease 0.6833333333333332\n",
      "--------day-------- 29\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 5.193333333333335\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.9828571428571424\n",
      "g_decrease 0.5695238095238095\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 2.1999999999999993\n",
      "g_decrease 0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 4.385714285714287\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0.6000000000000009\n",
      "g_decrease 0.7333333333333331\n",
      "--------day-------- 30\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.9742857142857135\n",
      "g_decrease 0.5695238095238095\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 2.3999999999999986\n",
      "g_decrease 0.6\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 5.450000000000002\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.3500000000000014\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 31\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.6266666666666654\n",
      "g_decrease 1.139047619047619\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 3.599999999999998\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 0\n",
      "g_decrease 1.9771428571428569\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.4000000000000017\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 32\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.3466666666666671\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 2.375\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 1.3999999999999968\n",
      "g_decrease 2.4\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 0.45000000000000023\n",
      "g_decrease 0\n",
      "--------day-------- 33\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 6.300000000000001\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0\n",
      "g_decrease 1.4171428571428573\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 0.2999999999999967\n",
      "g_decrease 3.2\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.06\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 0.9000000000000006\n",
      "g_decrease 0\n",
      "--------day-------- 34\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.5866666666666667\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 0\n",
      "g_decrease 3.2000000000000006\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.03\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 1.350000000000001\n",
      "g_decrease 0\n",
      "--------day-------- 35\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 2.171428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 3.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "g_increase 0\n",
      "g_decrease 1.1999999999999997\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 5.901428571428574\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 1.8000000000000014\n",
      "g_decrease 0\n",
      "--------day-------- 36\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.7000000000000002\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0.7699999999999998\n",
      "g_decrease 0.605\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.65\n",
      "g_increase 0\n",
      "g_decrease 3.600000000000001\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.450000000000002\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 37\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 2.571428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0.5399999999999994\n",
      "g_decrease 1.21\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.85\n",
      "g_increase 0\n",
      "g_decrease 1.4\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 0.4228571428571428\n",
      "g_decrease 0.9542857142857137\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 2.2500000000000013\n",
      "g_decrease 0\n",
      "--------day-------- 38\n",
      "running CUSUM algorithm\n",
      "troppo presto\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 5.375\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 0.9500000000000003\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 1.0828571428571425\n",
      "g_decrease 0.6628571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.5000000000000022\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 39\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.5533333333333337\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0\n",
      "g_decrease 1.7085714285714286\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 2.5100000000000007\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 6.352857142857146\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.250000000000001\n",
      "g_decrease 0\n",
      "--------day-------- 40\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 6.7366666666666655\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 1.014999999999999\n",
      "g_decrease 0.605\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 3.070000000000001\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0\n",
      "g_decrease 3.0900000000000003\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.9000000000000015\n",
      "g_decrease 0\n",
      "--------day-------- 41\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.843333333333331\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0.48999999999999866\n",
      "g_decrease 1.21\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 3.6300000000000012\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 1.2685714285714282\n",
      "g_decrease 0.6628571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0.5500000000000015\n",
      "g_decrease 1.3666666666666665\n",
      "--------day-------- 42\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.9000000000000012\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.6438095238095232\n",
      "g_decrease 1.139047619047619\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 5.97\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 2.165714285714285\n",
      "g_decrease 0.6628571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 1.700000000000001\n",
      "g_decrease 0.7499999999999999\n",
      "--------day-------- 43\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 2.6571428571428566\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.957142857142856\n",
      "g_decrease 1.139047619047619\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 6.919999999999998\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0.43571428571428594\n",
      "g_decrease 5.417142857142861\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.5500000000000025\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 44\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.949999999999997\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 7.869999999999998\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 5.481428571428576\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 0.6000000000000026\n",
      "g_decrease 1.1999999999999997\n",
      "--------day-------- 45\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.9285714285714286\n",
      "g_decrease 0.22857142857142781\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.9485714285714271\n",
      "g_decrease 0.8476190476190477\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 8.04\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 7.158571428571434\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 0.050000000000000044\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 46\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.242857142857143\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0.6009523809523789\n",
      "g_decrease 1.139047619047619\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 8.990000000000002\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 2.3514285714285705\n",
      "g_decrease 0.6628571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 0\n",
      "g_decrease 1.1999999999999997\n",
      "--------day-------- 47\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0.9428571428571426\n",
      "g_decrease 2.057142857142857\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 5.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 9.940000000000005\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 2.1500000000000012\n",
      "g_decrease 0\n",
      "--------day-------- 48\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.8666666666666685\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 6.125\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 9.500000000000007\n",
      "g_decrease 1.0199999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 1.7742857142857131\n",
      "g_decrease 1.3257142857142856\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 1.600000000000001\n",
      "g_decrease 0.7499999999999999\n",
      "--------day-------- 49\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0.6166666666666661\n",
      "g_decrease 6.833333333333329\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0\n",
      "g_decrease 1.2349999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 8.84000000000001\n",
      "g_decrease 1.5299999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0\n",
      "g_decrease 3.150000000000001\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.2000000000000017\n",
      "g_decrease 0.41666666666666646\n",
      "--------day-------- 50\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [14697.71567969 29395.43135938 44093.14703907 58790.86271876\n",
      " 73488.57839845]\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0.47999999999999876\n",
      "g_decrease 6.269999999999993\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0\n",
      "g_decrease 2.278095238095238\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 9.180000000000014\n",
      "g_decrease 1.0199999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.03333333333333299\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.850000000000002\n",
      "g_decrease 0\n",
      "--------day-------- 51\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0.21999999999999786\n",
      "g_decrease 5.929999999999992\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 6.25\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 9.740000000000016\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 8.061428571428577\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.5000000000000022\n",
      "g_decrease 0.6833333333333332\n",
      "--------day-------- 52\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.2571428571428567\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0.12499999999999976\n",
      "g_decrease 5.625\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 10.300000000000018\n",
      "g_decrease 0.5099999999999999\n",
      "------> detected change <-------\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0.11666666666666659\n",
      "g_decrease 2.5333333333333345\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 2.1500000000000026\n",
      "g_decrease 0\n",
      "--------day-------- 53\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.7999999999999994\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 5.875\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5599999999999999\n",
      "g_increase 0.5600000000000002\n",
      "g_decrease 0.5099999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 1.9599999999999986\n",
      "g_decrease 0.6628571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.800000000000003\n",
      "g_decrease 0.6833333333333332\n",
      "--------day-------- 54\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 6.143333333333323\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 1.3599999999999999\n",
      "g_decrease 0.605\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.06666666666666704\n",
      "g_decrease 0.416666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0.3500000000000002\n",
      "g_decrease 1.3533333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.6500000000000028\n",
      "g_decrease 0\n",
      "--------day-------- 55\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0.5333333333333331\n",
      "g_decrease 1.8333333333333357\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0\n",
      "g_decrease 2.42\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.13333333333333408\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7128571428571429\n",
      "g_increase 0\n",
      "g_decrease 2.6514285714285712\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.7000000000000028\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 56\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.342857142857142\n",
      "g_decrease 1.0857142857142854\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0\n",
      "g_decrease 1.6952380952380954\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 0.8833333333333332\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7266666666666667\n",
      "g_increase 0.4666666666666669\n",
      "g_decrease 0.7366666666666668\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.750000000000003\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 57\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.213333333333336\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6195238095238096\n",
      "g_increase 0\n",
      "g_decrease 2.9733333333333336\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.5333333333333328\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0\n",
      "g_decrease 10.351428571428578\n",
      "------> detected change <-------\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.8000000000000034\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 58\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.356666666666654\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 7.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.0833333333333338\n",
      "g_decrease 0.9499999999999992\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6628571428571428\n",
      "g_increase 0.7228571428571431\n",
      "g_decrease 0.6128571428571428\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.8500000000000036\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 59\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0.27142857142857046\n",
      "g_decrease 1.6571428571428566\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0.5499999999999996\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 2.3666666666666654\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.4466666666666663\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 0.9000000000000038\n",
      "g_decrease 1.1999999999999997\n",
      "--------day-------- 60\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9666666666666668\n",
      "g_increase 0\n",
      "g_decrease 0.9166666666666667\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 7.125\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 2.666666666666665\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 1.2733333333333325\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 1.4500000000000033\n",
      "g_decrease 0.7333333333333331\n",
      "--------day-------- 61\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 8.239999999999986\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 7.625\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.06666666666666704\n",
      "g_decrease 2.1999999999999984\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.5933333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.05\n",
      "g_decrease 0\n",
      "--------day-------- 62\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0.5333333333333331\n",
      "g_decrease 1.1800000000000033\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.425\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.15000000000000085\n",
      "g_decrease 1.616666666666665\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.5166666666666666\n",
      "g_decrease 0.5766666666666664\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.1\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 63\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.5600000000000036\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 8.0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.21666666666666795\n",
      "g_decrease 1.1499999999999981\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.5933333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.1500000000000004\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 64\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.5857142857142845\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0.47499999999999987\n",
      "g_decrease 1.4449999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.3000000000000018\n",
      "g_decrease 0.5666666666666642\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.576666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.2000000000000006\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 65\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.8999999999999986\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.655\n",
      "g_increase 0.35999999999999965\n",
      "g_decrease 1.2599999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.3833333333333357\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.8266666666666664\n",
      "g_decrease 0.9499999999999997\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 1.0500000000000012\n",
      "g_decrease 0.9999999999999997\n",
      "--------day-------- 66\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.8285714285714274\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 10.125\n",
      "------> detected change <-------\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 0.8833333333333332\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 1.2399999999999995\n",
      "g_decrease 0.13666666666666638\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.2500000000000009\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 67\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.37142857142857\n",
      "g_decrease 1.0857142857142854\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.925\n",
      "g_increase 0\n",
      "g_decrease 1.75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.416666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.7566666666666659\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0.10000000000000342\n",
      "g_decrease 1.7833333333333328\n",
      "--------day-------- 68\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.676666666666652\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.083333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.06666666666666704\n",
      "g_decrease 0.9499999999999992\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.47999999999999887\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.950000000000004\n",
      "g_decrease 0\n",
      "--------day-------- 69\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 8.113333333333317\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0.45833333333333304\n",
      "g_decrease 1.1250000000000007\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.483333333333332\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.5933333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 3.000000000000004\n",
      "g_decrease 0\n",
      "--------day-------- 70\n",
      "Abrupt change\n",
      "class User 0 has changed: its new average reservation price is [17637.25881563 35274.51763126 52911.77644689 70549.03526252\n",
      " 88186.29407815]\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 3.0857142857142854\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0.37499999999999867\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.0833333333333338\n",
      "g_decrease 0.8999999999999985\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.373333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 4.050000000000004\n",
      "g_decrease 0\n",
      "--------day-------- 71\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.549999999999982\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.15000000000000085\n",
      "g_decrease 0.4333333333333313\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.1533333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 4.100000000000003\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 72\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 8.53999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.6166666666666667\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 0.8833333333333332\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.5266666666666664\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.150000000000002\n",
      "g_decrease 0\n",
      "--------day-------- 73\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0.42666666666666647\n",
      "g_decrease 0.7333333333333374\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.4666666666666668\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.2999999999999992\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.3066666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 4.200000000000001\n",
      "g_decrease 1.0999999999999999\n",
      "--------day-------- 74\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 1.1733333333333327\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.1250000000000002\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.10000000000000056\n",
      "g_decrease 0.5999999999999985\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.2733333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 4.25\n",
      "g_decrease 0.7499999999999998\n",
      "--------day-------- 75\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0.4933333333333326\n",
      "g_decrease 0.7933333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.5500000000000003\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.2499999999999982\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.0533333333333337\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.299999999999999\n",
      "g_decrease 0\n",
      "--------day-------- 76\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0\n",
      "g_decrease 3.171428571428571\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.4000000000000004\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.6666666666666643\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.6199999999999999\n",
      "g_decrease 0.8333333333333335\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.349999999999998\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 77\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9666666666666668\n",
      "g_increase 0\n",
      "g_decrease 0.5833333333333337\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 2.2500000000000004\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 2.083333333333331\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.23999999999999955\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.399999999999997\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 78\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0.7399999999999993\n",
      "g_decrease 7.19999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.7166666666666675\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.10000000000000056\n",
      "g_decrease 1.3833333333333306\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.27333333333333254\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.449999999999996\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 79\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 8.083333333333313\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0.5499999999999996\n",
      "g_decrease 0.5666666666666675\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.9166666666666639\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.9966666666666656\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.499999999999995\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 80\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.3142857142857143\n",
      "g_decrease 1.2571428571428562\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 1.099999999999999\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.0833333333333338\n",
      "g_decrease 1.3333333333333304\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 1.823333333333332\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 5.549999999999994\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 81\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0.8571428571428572\n",
      "g_decrease 1.3142857142857132\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0.37499999999999867\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.9833333333333303\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 1.1333333333333317\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 4.5999999999999925\n",
      "g_decrease 1.1999999999999997\n",
      "--------day-------- 82\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.966666666666645\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 1.0166666666666648\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.0833333333333338\n",
      "g_decrease 1.3999999999999968\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.5933333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 3.649999999999992\n",
      "g_decrease 1.8499999999999996\n",
      "--------day-------- 83\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.7857142857142856\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 1.5666666666666642\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.1833333333333344\n",
      "g_decrease 0.6999999999999963\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.6199999999999999\n",
      "g_decrease 0.37333333333333313\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.3000000000000012\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 84\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 0.714285714285714\n",
      "g_decrease 1.5428571428571427\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 1.2083333333333306\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.2666666666666683\n",
      "g_decrease 0.11666666666666246\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.23999999999999955\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 0.5000000000000014\n",
      "g_decrease 1.2499999999999993\n",
      "--------day-------- 85\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.626666666666643\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0\n",
      "g_decrease 1.6583333333333337\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 1.7666666666666664\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.8599999999999993\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.3500000000000014\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 86\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 0.9666666666666668\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 0.45833333333333304\n",
      "g_decrease 0.7000000000000004\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 3.8333333333333326\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 1.479999999999999\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.699999999999992\n",
      "g_decrease 2.4999999999999996\n",
      "--------day-------- 87\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 8.063333333333308\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 1.0083333333333324\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.10000000000000056\n",
      "g_decrease 3.1333333333333324\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.20333333333333203\n",
      "g_decrease 1.5933333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.4000000000000017\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 88\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8433333333333334\n",
      "g_increase 0\n",
      "g_decrease 0.9333333333333338\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 1.4666666666666652\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 3.549999999999999\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.1699999999999997\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 0.9500000000000017\n",
      "g_decrease 0.4999999999999993\n",
      "--------day-------- 89\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 1.4142857142857137\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 2.291666666666665\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.13333333333333408\n",
      "g_decrease 2.6166666666666654\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.9299999999999997\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7999999999999999\n",
      "g_increase 0.400000000000002\n",
      "g_decrease 0.7499999999999999\n",
      "--------day-------- 90\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.342857142857142\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 3.0249999999999995\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 3.033333333333332\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 2.3899999999999997\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0\n",
      "g_decrease 1.8333333333333326\n",
      "--------day-------- 91\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 2.814285714285714\n",
      "g_decrease 1.5428571428571427\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 3.3916666666666666\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 3.3333333333333317\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.7233333333333332\n",
      "g_decrease 0.9666666666666663\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.450000000000002\n",
      "g_decrease 0\n",
      "--------day-------- 92\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 4.128571428571428\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 2.9416666666666673\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 4.8666666666666645\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.23999999999999955\n",
      "g_decrease 0.9499999999999996\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.500000000000002\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 93\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 5.057142857142859\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 3.3083333333333345\n",
      "g_decrease 0.04166666666666691\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 5.283333333333329\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.8599999999999993\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.5500000000000025\n",
      "g_decrease 0.5499999999999999\n",
      "--------day-------- 94\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 6.371428571428575\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 2.858333333333335\n",
      "g_decrease 0.8083333333333333\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.06666666666666704\n",
      "g_decrease 4.81666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0.3766666666666658\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 1.6000000000000028\n",
      "g_decrease 1.1999999999999997\n",
      "--------day-------- 95\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 6.300000000000006\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 3.316666666666669\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 5.116666666666657\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.7333333333333333\n",
      "g_increase 0\n",
      "g_decrease 1.8833333333333324\n",
      "--------day-------- 96\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 7.614285714285723\n",
      "g_decrease 0.5142857142857142\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 3.9583333333333366\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.0833333333333338\n",
      "g_decrease 4.533333333333322\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.7499999999999925\n",
      "g_decrease 2.1499999999999995\n",
      "--------day-------- 97\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.5642857142857143\n",
      "g_increase 7.157142857142867\n",
      "g_decrease 1.0285714285714285\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 4.233333333333337\n",
      "g_decrease 0\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 5.066666666666653\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 0.7966666666666666\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 2.7999999999999927\n",
      "g_decrease 1.7999999999999994\n",
      "--------day-------- 98\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.94666666666664\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 2.691666666666671\n",
      "g_decrease 1.6166666666666667\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0.0833333333333338\n",
      "g_decrease 4.483333333333317\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.7799999999999998\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 3.849999999999993\n",
      "g_decrease 0.44999999999999946\n",
      "--------day-------- 99\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8266666666666668\n",
      "g_increase 0\n",
      "g_decrease 7.829999999999972\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8583333333333334\n",
      "g_increase 2.150000000000005\n",
      "g_decrease 1.6583333333333334\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.9333333333333332\n",
      "g_increase 0\n",
      "g_decrease 5.016666666666649\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.8466666666666667\n",
      "g_increase 0\n",
      "g_decrease 1.3566666666666662\n",
      "running CUSUM algorithm\n",
      "mean_over_M:  0.6\n",
      "g_increase 3.899999999999993\n",
      "g_decrease 0.5499999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison between CUSUM-UCB and UCB\n",
    "# dynamic environment\n",
    "\n",
    "n_arms = 4\n",
    "num_users = 100\n",
    "n_days = 100\n",
    "fixed_alpha = 1\n",
    "fixed_weights = 0\n",
    "fixed_units = 1  # 0 ?\n",
    "n_experiments = 1\n",
    "\n",
    "window_size = 50\n",
    "\n",
    "days_of_change = [50, 70]\n",
    "\n",
    "\n",
    "cd_ucb_rewards_per_experiment = []\n",
    "ucb_rewards_per_experiment = []\n",
    "\n",
    "cd_ucb_pulls_per_arm_per_experiment = []\n",
    "ucb_pulls_per_arm_per_experiment = []\n",
    "\n",
    "\n",
    "for e in range(n_experiments):\n",
    "\n",
    "    env = Environment(n_arms, E, margins_matrix, num_users, fixed_alpha,fixed_weights,fixed_units)\n",
    "    ucb_learner = UCB(n_arms=n_arms)\n",
    "    cd_UCB_learner = CUSUM_UCB(n_arms, window_size)\n",
    "\n",
    "    for d in range(n_days):\n",
    "        print('--------day--------', d)\n",
    "        for day_of_change in days_of_change:\n",
    "            if d==day_of_change:\n",
    "                env.abrupt_change([0],1.20)\n",
    "\n",
    "        pulled_arm = ucb_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        ucb_learner.update(pulled_arm, reward)\n",
    "\n",
    "        pulled_arm = cd_UCB_learner.pull_arm()\n",
    "        reward = env.round(pulled_arm)\n",
    "        cd_UCB_learner.update(pulled_arm, reward, env.purchases_current_day,env.clicks_current_day)\n",
    "\n",
    "    cd_ucb_rewards_per_experiment.append(cd_UCB_learner.collected_rewards)\n",
    "    ucb_rewards_per_experiment.append(ucb_learner.collected_rewards)\n",
    "\n",
    "\n",
    "    cd_ucb_pulls_per_arm_per_experiment.append(cd_UCB_learner.counter_per_arm)\n",
    "    ucb_pulls_per_arm_per_experiment.append(ucb_learner.counter_per_arm)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Rewards:\")\n",
    "plt.plot(np.cumsum(np.mean(cd_ucb_rewards_per_experiment, axis=0)), 'r')\n",
    "plt.plot(np.cumsum(np.mean(ucb_rewards_per_experiment, axis=0)), 'b')\n",
    "plt.legend([\"CUSUM-UCB\",\"UCB\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1838362fc3c72254db1311c9d5db56b79b6520b93de3800103ebfd8112b592e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}